{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import string\n",
    "import random\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "from nltk.corpus import reuters\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package reuters to\n",
      "[nltk_data]     C:\\Users\\flori\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package reuters is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10788"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load 10k reuters news documents \n",
    "nltk.download('reuters')\n",
    "len(reuters.fileids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"ASIAN EXPORTERS FEAR DAMAGE FROM U.S.-JAPAN RIFT\\n  Mounting trade friction between the\\n  U.S. And Japan has raised fears among many of Asia's exporting\\n  nations that the row could inflict far-reaching\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#view text from one document \n",
    "reuters.raw(fileids=['test/14826'])[0:201]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHINA DAILY SAYS VERMIN EAT 712 PCT GRAIN STOCKS\n",
      "  A survey of 19 provinces and seven cities\n",
      "  showed vermin consume between seven and 12 pct of Chinas grain\n",
      "  stocks the China Daily said\n",
      "      It also said that each year 1575 mln tonnes or 25 pct of\n",
      "  Chinas fruit output are left to rot and 21 mln tonnes or up\n",
      "  to 30 pct of its vegetables The paper blamed the waste on\n",
      "  inadequate storage and bad preservation methods\n",
      "      It said the government had launched a national programme to\n",
      "  reduce waste calling for improved technology in storage and\n",
      "  preservation and greater production of additives The paper\n",
      "  gave no further details\n",
      "  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# remove punctuation from all DOCs \n",
    "exclude = set(string.punctuation)\n",
    "alldocslist = []\n",
    "\n",
    "for index, i in  enumerate(reuters.fileids()):\n",
    "    text = reuters.raw(fileids=[i])\n",
    "    text = ''.join(ch for ch in text if ch not in exclude)\n",
    "    alldocslist.append(text)\n",
    "    \n",
    "print(alldocslist[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CHINA', 'DAILY', 'SAYS', 'VERMIN', 'EAT', '712', 'PCT', 'GRAIN', 'STOCKS', 'A', 'survey', 'of', '19', 'provinces', 'and', 'seven', 'cities', 'showed', 'vermin', 'consume', 'between', 'seven', 'and', '12', 'pct', 'of', 'Chinas', 'grain', 'stocks', 'the', 'China', 'Daily', 'said', 'It', 'also', 'said', 'that', 'each', 'year', '1575', 'mln', 'tonnes', 'or', '25', 'pct', 'of', 'Chinas', 'fruit', 'output', 'are', 'left', 'to', 'rot', 'and', '21', 'mln', 'tonnes', 'or', 'up', 'to', '30', 'pct', 'of', 'its', 'vegetables', 'The', 'paper', 'blamed', 'the', 'waste', 'on', 'inadequate', 'storage', 'and', 'bad', 'preservation', 'methods', 'It', 'said', 'the', 'government', 'had', 'launched', 'a', 'national', 'programme', 'to', 'reduce', 'waste', 'calling', 'for', 'improved', 'technology', 'in', 'storage', 'and', 'preservation', 'and', 'greater', 'production', 'of', 'additives', 'The', 'paper', 'gave', 'no', 'further', 'details']\n"
     ]
    }
   ],
   "source": [
    "#tokenize words in all DOCS \n",
    "plot_data = [[]] * len(alldocslist)\n",
    "\n",
    "for doc in alldocslist:\n",
    "    text = doc\n",
    "    tokentext = word_tokenize(text)\n",
    "    plot_data[index].append(tokentext)\n",
    "    \n",
    "print(plot_data[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CHINA',\n",
       " 'DAILY',\n",
       " 'SAYS',\n",
       " 'VERMIN',\n",
       " 'EAT',\n",
       " '712',\n",
       " 'PCT',\n",
       " 'GRAIN',\n",
       " 'STOCKS',\n",
       " 'A']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Navigation: first index gives all documents, second index gives specific document, third index gives words of that doc\n",
    "plot_data[0][1][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['china',\n",
       " 'daily',\n",
       " 'says',\n",
       " 'vermin',\n",
       " 'eat',\n",
       " '712',\n",
       " 'pct',\n",
       " 'grain',\n",
       " 'stocks',\n",
       " 'a']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make all words lower case for all docs \n",
    "for x in range(len(reuters.fileids())):\n",
    "    lowers = [word.lower() for word in plot_data[0][x]]\n",
    "    plot_data[0][x] = lowers\n",
    "\n",
    "plot_data[0][1][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['china',\n",
       " 'daily',\n",
       " 'says',\n",
       " 'vermin',\n",
       " 'eat',\n",
       " '712',\n",
       " 'pct',\n",
       " 'grain',\n",
       " 'stocks',\n",
       " 'survey']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove stop words from all docs \n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "for x in range(len(reuters.fileids())):\n",
    "    filtered_sentence = [w for w in plot_data[0][x] if not w in stop_words]\n",
    "    plot_data[0][x] = filtered_sentence\n",
    "\n",
    "plot_data[0][1][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ltaha',\n",
       " 'automot',\n",
       " 'technolog',\n",
       " 'corp',\n",
       " 'year',\n",
       " 'net',\n",
       " 'shr',\n",
       " '43',\n",
       " 'ct',\n",
       " 'vs']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stem words EXAMPLE (could try others/lemmers )\n",
    "\n",
    "snowball_stemmer = SnowballStemmer(\"english\")\n",
    "stemmed_sentence = [snowball_stemmer.stem(w) for w in filtered_sentence]\n",
    "stemmed_sentence[0:10]\n",
    "\n",
    "porter_stemmer = PorterStemmer()\n",
    "snowball_stemmer = SnowballStemmer(\"english\")\n",
    "stemmed_sentence = [ porter_stemmer.stem(w) for w in filtered_sentence]\n",
    "stemmed_sentence[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create inverse index which gives document number for each document and where word appears\n",
    "\n",
    "#first we need to create a list of all words \n",
    "l = plot_data[0]\n",
    "flatten = [item for sublist in l for item in sublist]\n",
    "words = flatten\n",
    "wordsunique = set(words)\n",
    "wordsunique = list(wordsunique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create functions for TD-IDF / BM25\n",
    "import math\n",
    "from textblob import TextBlob as tb\n",
    "\n",
    "def tf(word, doc):\n",
    "    return doc.count(word) / len(doc)\n",
    "\n",
    "def n_containing(word, doclist):\n",
    "    return sum(1 for doc in doclist if word in doc)\n",
    "\n",
    "def idf(word, doclist):\n",
    "    return math.log(len(doclist) / (0.01 + n_containing(word, doclist)))\n",
    "\n",
    "def tfidf(word, doc, doclist):\n",
    "    return (tf(word, doc) * idf(word, doclist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictonary of words\n",
    "# THIS ONE-TIME INDEXING IS THE MOST PROCESSOR-INTENSIVE STEP AND WILL TAKE TIME TO RUN (BUT ONLY NEEDS TO BE RUN ONCE)\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "plottest = plot_data[0][0:1000]\n",
    "\n",
    "worddic = {}\n",
    "\n",
    "for doc in plottest:\n",
    "    for word in wordsunique:\n",
    "        if word in doc:\n",
    "            word = str(word)\n",
    "            index = plottest.index(doc)\n",
    "            positions = list(np.where(np.array(plottest[index]) == word)[0])\n",
    "            idfs = tfidf(word,doc,plottest)\n",
    "            try:\n",
    "                worddic[word].append([index,positions,idfs])\n",
    "            except:\n",
    "                worddic[word] = []\n",
    "                worddic[word].append([index,positions,idfs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, [0, 23], 0.1131500878815288],\n",
       " [13, [0], 0.06694713532990454],\n",
       " [14, [160], 0.013213250394060107],\n",
       " [28, [51], 0.05821490028687352],\n",
       " [40, [3, 15, 59, 79], 0.14740653650621185],\n",
       " [236, [86], 0.04414096834938761],\n",
       " [281, [70], 0.0565750439407644],\n",
       " [293, [13, 21], 0.11642980057374704],\n",
       " [302, [33], 0.059952658504392124],\n",
       " [342, [55, 146], 0.05391715597039292],\n",
       " [567, [2], 0.06925565723783228],\n",
       " [569, [1014, 1072, 1221], 0.009248261212112677],\n",
       " [612, [20], 0.01998421950146404],\n",
       " [710, [0, 7, 34], 0.17464470086062053],\n",
       " [720, [0, 16], 0.23628400704672192],\n",
       " [721, [0, 6, 27, 78, 82], 0.2028701070603168],\n",
       " [733, [179], 0.021595850106420823],\n",
       " [736, [0, 5, 21, 83], 0.13732745708698368]]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the index creates a dic with each word as a KEY and a list of doc indexs, word positions, and td-idf score as VALUES\n",
    "worddic['china']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickel (save) the dictonary to avoid re-calculating\n",
    "np.save('worddic_1000.npy', worddic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['indonesia', 'crude', 'palm', 'oil']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create word search which takes multiple words and finds documents that contain both along with metrics for ranking:\n",
    "\n",
    "    ## (1) Number of occruances of search words \n",
    "    ## (2) TD-IDF score for search words \n",
    "    ## (3) Percentage of search terms\n",
    "    ## (4) Word ordering score \n",
    "    ## (5) Exact match bonus \n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "def search(searchsentence):\n",
    "    try:\n",
    "        # split sentence into individual words \n",
    "        searchsentence = searchsentence.lower()\n",
    "        try:\n",
    "            words = searchsentence.split(' ')\n",
    "        except:\n",
    "            words = list(words)\n",
    "        enddic = {}\n",
    "        idfdic = {}\n",
    "        closedic = {}\n",
    "        \n",
    "        # remove words if not in worddic \n",
    "        realwords = []\n",
    "        for word in words:\n",
    "            if word in list(worddic.keys()):\n",
    "                realwords.append(word)  \n",
    "        words = realwords\n",
    "        numwords = len(words)\n",
    "        \n",
    "        # make metric of number of occurances of all words in each doc & largest total IDF \n",
    "        for word in words:\n",
    "            for indpos in worddic[word]:\n",
    "                index = indpos[0]\n",
    "                amount = len(indpos[1])\n",
    "                idfscore = indpos[2]\n",
    "                enddic[index] = amount\n",
    "                idfdic[index] = idfscore\n",
    "                fullcount_order = sorted(enddic.items(), key=lambda x:x[1], reverse=True)\n",
    "                fullidf_order = sorted(idfdic.items(), key=lambda x:x[1], reverse=True)\n",
    "\n",
    "                \n",
    "        # make metric of what percentage of words appear in each doc\n",
    "        combo = []\n",
    "        alloptions = {k: worddic.get(k, None) for k in (words)}\n",
    "        for worddex in list(alloptions.values()):\n",
    "            for indexpos in worddex:\n",
    "                for indexz in indexpos:\n",
    "                    combo.append(indexz)\n",
    "        comboindex = combo[::3]\n",
    "        combocount = Counter(comboindex)\n",
    "        for key in combocount:\n",
    "            combocount[key] = combocount[key] / numwords\n",
    "        combocount_order = sorted(combocount.items(), key=lambda x:x[1], reverse=True)\n",
    "        \n",
    "        # make metric for if words appear in same order as in search\n",
    "        if len(words) > 1:\n",
    "            x = []\n",
    "            y = []\n",
    "            for record in [worddic[z] for z in words]:\n",
    "                for index in record:\n",
    "                     x.append(index[0])\n",
    "            for i in x:\n",
    "                if x.count(i) > 1:\n",
    "                    y.append(i)\n",
    "            y = list(set(y))\n",
    "\n",
    "            closedic = {}\n",
    "            for wordbig in [worddic[x] for x in words]:\n",
    "                for record in wordbig:\n",
    "                    if record[0] in y:\n",
    "                        index = record[0]\n",
    "                        positions = record[1]\n",
    "                        try:\n",
    "                            closedic[index].append(positions)\n",
    "                        except:\n",
    "                            closedic[index] = []\n",
    "                            closedic[index].append(positions)\n",
    "\n",
    "            x = 0\n",
    "            fdic = {}\n",
    "            for index in y:\n",
    "                csum = []\n",
    "                for seqlist in closedic[index]:\n",
    "                    while x > 0:\n",
    "                        secondlist = seqlist\n",
    "                        x = 0\n",
    "                        sol = [1 for i in firstlist if i + 1 in secondlist]\n",
    "                        csum.append(sol)\n",
    "                        fsum = [item for sublist in csum for item in sublist]\n",
    "                        fsum = sum(fsum)\n",
    "                        fdic[index] = fsum\n",
    "                        fdic_order = sorted(fdic.items(), key=lambda x:x[1], reverse=True)\n",
    "                    while x == 0:\n",
    "                        firstlist = seqlist\n",
    "                        x = x + 1\n",
    "        else:\n",
    "            fdic_order = 0\n",
    "                    \n",
    "        # also the one above should be given a big boost if ALL found together \n",
    "           \n",
    "        \n",
    "        #could make another metric for if they are not next to each other but still close \n",
    "        \n",
    "        \n",
    "        return(searchsentence,words,fullcount_order,combocount_order,fullidf_order,fdic_order)\n",
    "    \n",
    "    except:\n",
    "        return(\"\")\n",
    "\n",
    "\n",
    "search('indonesia crude palm oil')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['crude', 'palm', 'oil']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0 return will give back the search term, the rest will give back metrics (see above)\n",
    "\n",
    "search('indonesia crude palm oil')[1][1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>search term</th>\n",
       "      <th>actual_words_searched</th>\n",
       "      <th>num_occur</th>\n",
       "      <th>percentage_of_terms</th>\n",
       "      <th>td-idf</th>\n",
       "      <th>word_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>china daily says what</td>\n",
       "      <td>[china, daily, says]</td>\n",
       "      <td>[(183, 5), (40, 4), (569, 3), (710, 3), (342, ...</td>\n",
       "      <td>[(1, 1.0), (13, 0.6666666666666666), (14, 0.66...</td>\n",
       "      <td>[(675, 0.5095658223243495), (135, 0.4367707048...</td>\n",
       "      <td>[(1, 3), (293, 1), (720, 1), (721, 1), (736, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>indonesia crude palm oil</td>\n",
       "      <td>[indonesia, crude, palm, oil]</td>\n",
       "      <td>[(33, 13), (621, 12), (34, 11), (209, 8), (123...</td>\n",
       "      <td>[(4, 1.0), (6, 1.0), (209, 0.5), (281, 0.5), (...</td>\n",
       "      <td>[(762, 0.48707909813666866), (266, 0.434203698...</td>\n",
       "      <td>[(34, 6), (4, 5), (660, 5), (6, 4), (268, 2), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>price of nickel</td>\n",
       "      <td>[price, nickel]</td>\n",
       "      <td>[(572, 19), (639, 8), (108, 7), (148, 7), (736...</td>\n",
       "      <td>[(724, 1.0), (4, 0.5), (7, 0.5), (20, 0.5), (2...</td>\n",
       "      <td>[(50, 0.24460301234499893), (537, 0.2066299280...</td>\n",
       "      <td>[(724, 0)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>north yemen sugar</td>\n",
       "      <td>[north, yemen, sugar]</td>\n",
       "      <td>[(700, 12), (96, 8), (494, 7), (296, 6), (525,...</td>\n",
       "      <td>[(30, 1.0), (758, 1.0), (47, 0.666666666666666...</td>\n",
       "      <td>[(494, 0.3808351739278394), (30, 0.35115970582...</td>\n",
       "      <td>[(758, 2), (30, 2), (851, 0), (47, 0)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nippon steel</td>\n",
       "      <td>[nippon, steel]</td>\n",
       "      <td>[(40, 9), (253, 8), (444, 7), (223, 2), (435, ...</td>\n",
       "      <td>[(40, 1.0), (123, 0.5), (223, 0.5), (253, 0.5)...</td>\n",
       "      <td>[(223, 0.5682589478261134), (40, 0.42228417223...</td>\n",
       "      <td>[(40, 5)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>china</td>\n",
       "      <td>[china]</td>\n",
       "      <td>[(721, 5), (40, 4), (736, 4), (569, 3), (710, ...</td>\n",
       "      <td>[(1, 1.0), (13, 1.0), (14, 1.0), (28, 1.0), (4...</td>\n",
       "      <td>[(720, 0.23628400704672192), (721, 0.202870107...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gold</td>\n",
       "      <td>[gold]</td>\n",
       "      <td>[(997, 6), (20, 5), (797, 5), (341, 4), (347, ...</td>\n",
       "      <td>[(8, 1.0), (12, 1.0), (20, 1.0), (32, 1.0), (2...</td>\n",
       "      <td>[(304, 0.30902054113001826), (20, 0.2575171176...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>trade</td>\n",
       "      <td>[trade]</td>\n",
       "      <td>[(0, 15), (169, 10), (544, 10), (761, 8), (273...</td>\n",
       "      <td>[(285, 2.0), (701, 2.0), (713, 2.0), (923, 2.0...</td>\n",
       "      <td>[(223, 0.24728127372797265), (449, 0.247281273...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                search term          actual_words_searched  \\\n",
       "0     china daily says what           [china, daily, says]   \n",
       "1  indonesia crude palm oil  [indonesia, crude, palm, oil]   \n",
       "2           price of nickel                [price, nickel]   \n",
       "3         north yemen sugar          [north, yemen, sugar]   \n",
       "4              nippon steel                [nippon, steel]   \n",
       "5                     china                        [china]   \n",
       "6                      gold                         [gold]   \n",
       "7                     trade                        [trade]   \n",
       "\n",
       "                                           num_occur  \\\n",
       "0  [(183, 5), (40, 4), (569, 3), (710, 3), (342, ...   \n",
       "1  [(33, 13), (621, 12), (34, 11), (209, 8), (123...   \n",
       "2  [(572, 19), (639, 8), (108, 7), (148, 7), (736...   \n",
       "3  [(700, 12), (96, 8), (494, 7), (296, 6), (525,...   \n",
       "4  [(40, 9), (253, 8), (444, 7), (223, 2), (435, ...   \n",
       "5  [(721, 5), (40, 4), (736, 4), (569, 3), (710, ...   \n",
       "6  [(997, 6), (20, 5), (797, 5), (341, 4), (347, ...   \n",
       "7  [(0, 15), (169, 10), (544, 10), (761, 8), (273...   \n",
       "\n",
       "                                 percentage_of_terms  \\\n",
       "0  [(1, 1.0), (13, 0.6666666666666666), (14, 0.66...   \n",
       "1  [(4, 1.0), (6, 1.0), (209, 0.5), (281, 0.5), (...   \n",
       "2  [(724, 1.0), (4, 0.5), (7, 0.5), (20, 0.5), (2...   \n",
       "3  [(30, 1.0), (758, 1.0), (47, 0.666666666666666...   \n",
       "4  [(40, 1.0), (123, 0.5), (223, 0.5), (253, 0.5)...   \n",
       "5  [(1, 1.0), (13, 1.0), (14, 1.0), (28, 1.0), (4...   \n",
       "6  [(8, 1.0), (12, 1.0), (20, 1.0), (32, 1.0), (2...   \n",
       "7  [(285, 2.0), (701, 2.0), (713, 2.0), (923, 2.0...   \n",
       "\n",
       "                                              td-idf  \\\n",
       "0  [(675, 0.5095658223243495), (135, 0.4367707048...   \n",
       "1  [(762, 0.48707909813666866), (266, 0.434203698...   \n",
       "2  [(50, 0.24460301234499893), (537, 0.2066299280...   \n",
       "3  [(494, 0.3808351739278394), (30, 0.35115970582...   \n",
       "4  [(223, 0.5682589478261134), (40, 0.42228417223...   \n",
       "5  [(720, 0.23628400704672192), (721, 0.202870107...   \n",
       "6  [(304, 0.30902054113001826), (20, 0.2575171176...   \n",
       "7  [(223, 0.24728127372797265), (449, 0.247281273...   \n",
       "\n",
       "                                          word_order  \n",
       "0  [(1, 3), (293, 1), (720, 1), (721, 1), (736, 0...  \n",
       "1  [(34, 6), (4, 5), (660, 5), (6, 4), (268, 2), ...  \n",
       "2                                         [(724, 0)]  \n",
       "3             [(758, 2), (30, 2), (851, 0), (47, 0)]  \n",
       "4                                          [(40, 5)]  \n",
       "5                                                  0  \n",
       "6                                                  0  \n",
       "7                                                  0  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save metrics to dataframe for use in ranking and machine learning \n",
    "result1 = search('china daily says what')\n",
    "result2 = search('indonesia crude palm oil')\n",
    "result3 = search('price of nickel')\n",
    "result4 = search('north yemen sugar')\n",
    "result5 = search('nippon steel')\n",
    "result6 = search('China')\n",
    "result7 = search('Gold')\n",
    "result8 = search('trade')\n",
    "df = pd.DataFrame([result1,result2,result3,result4,result5,result6,result7,result8])\n",
    "df.columns = ['search term', 'actual_words_searched','num_occur','percentage_of_terms','td-idf','word_order']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CHINA DAILY SAYS VERMIN EAT 712 PCT GRAIN STOCKS\\n  A survey of 19 provinces and seven cities\\n  showed vermin consume between seven and 12 pct of Chinas grain\\n  stocks the China Daily said\\n      It also said that each year 1575 mln tonnes or 25 pct of\\n  Chinas fruit output are left to rot and 21 mln tonnes or up\\n  to 30 pct of its vegetables The paper blamed the waste on\\n  inadequate storage and bad preservation methods\\n      It said the government had launched a national programme to\\n  reduce waste calling for improved technology in storage and\\n  preservation and greater production of additives The paper\\n  gave no further details\\n  \\n\\n'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look to see if the top documents seem to make sense\n",
    "\n",
    "alldocslist[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a simple (non-machine learning) rank and return function\n",
    "\n",
    "def rank(term):\n",
    "    results = search(term)\n",
    "\n",
    "    # get metrics \n",
    "    num_score = results[2]\n",
    "    per_score = results[3]\n",
    "    tfscore = results[4]\n",
    "    order_score = results[5]\n",
    "    \n",
    "    final_candidates = []\n",
    "\n",
    "    # rule1: if high word order score & 100% percentage terms then put at top position\n",
    "    try:\n",
    "        first_candidates = []\n",
    "\n",
    "        for candidates in order_score:\n",
    "            if candidates[1] > 1:\n",
    "                first_candidates.append(candidates[0])\n",
    "\n",
    "        second_candidates = []\n",
    "\n",
    "        for match_candidates in per_score:\n",
    "            if match_candidates[1] == 1:\n",
    "                second_candidates.append(match_candidates[0])\n",
    "            if match_candidates[1] == 1 and match_candidates[0] in first_candidates:\n",
    "                final_candidates.append(match_candidates[0])\n",
    "\n",
    "    # rule2: next add other word order score which are greater than 1 \n",
    "\n",
    "        t3_order = first_candidates[0:3]\n",
    "        for each in t3_order:\n",
    "            if each not in final_candidates:\n",
    "                final_candidates.insert(len(final_candidates),each)\n",
    "\n",
    "    # rule3: next add top td-idf results\n",
    "        final_candidates.insert(len(final_candidates),tfscore[0][0])\n",
    "        final_candidates.insert(len(final_candidates),tfscore[1][0])\n",
    "\n",
    "    # rule4: next add other high percentage score \n",
    "        t3_per = second_candidates[0:3]\n",
    "        for each in t3_per:\n",
    "            if each not in final_candidates:\n",
    "                final_candidates.insert(len(final_candidates),each)\n",
    "\n",
    "    #rule5: next add any other top results for metrics\n",
    "        othertops = [num_score[0][0],per_score[0][0],tfscore[0][0],order_score[0][0]]\n",
    "        for top in othertops:\n",
    "            if top not in final_candidates:\n",
    "                final_candidates.insert(len(final_candidates),top)\n",
    "                \n",
    "    # unless single term searched, in which case just return \n",
    "    except:\n",
    "        othertops = [num_score[0][0],num_score[1][0],num_score[2][0],per_score[0][0],tfscore[0][0]]\n",
    "        for top in othertops:\n",
    "            if top not in final_candidates:\n",
    "                final_candidates.insert(len(final_candidates),top)\n",
    "\n",
    "    for index, results in enumerate(final_candidates):\n",
    "        if index < 5:\n",
    "            print(\"RESULT\", index + 1, \":\", alldocslist[results][0:100],\"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULT 1 : INDONESIA SEES CPO PRICE RISING SHARPLY\n",
      "  Indonesia expects crude palm oil CPO\n",
      "  prices to rise shar ...\n",
      "RESULT 2 : INDONESIAN COMMODITY EXCHANGE MAY EXPAND\n",
      "  The Indonesian Commodity Exchange is\n",
      "  likely to start tr ...\n",
      "RESULT 3 : MALAYSIA MAY NOT MEET 1987 OIL PALM TARGET\n",
      "  Malaysia is unlikely to meet its\n",
      "  targeted output of f ...\n",
      "RESULT 4 : SAUDI ARABIA SEEKING RBD PALM OLEIN\n",
      "  Saudi Arabia is in the market for 4000\n",
      "  tonnes of refined ble ...\n",
      "RESULT 5 : SAUDI ARABIA BUYS RBD PALM OLEIN\n",
      "  Saudi Arabia bought 4000 tonnes of\n",
      "  Malaysian refined bleached d ...\n"
     ]
    }
   ],
   "source": [
    "# example of output \n",
    "rank('indonesia palm oil')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULT 1 : CHINA CHILE TO BUILD COPPER TUBE PLANT IN CHINA\n",
      "  Chinas stateowned Beijing NonFerrous\n",
      "  Metals Indu ...\n",
      "RESULT 2 : NIPPON STEEL DENIES CHINA SEEKING JAPANESE PLANTS\n",
      "  Nippon Steel Corp ltNSTCT denied local\n",
      "  newspap ...\n",
      "RESULT 3 : CHINA RAISES GRAIN PURCHASE PRICES\n",
      "  China has raised the state purchase\n",
      "  prices of corn rice cotto ...\n",
      "RESULT 4 : CHINA DAILY SAYS VERMIN EAT 712 PCT GRAIN STOCKS\n",
      "  A survey of 19 provinces and seven cities\n",
      "  showe ...\n",
      "RESULT 5 : CHINA SULPHURIRON MINE STARTS PRODUCTION\n",
      "  Chinas largest sulphuriron mine has\n",
      "  started trial produ ...\n"
     ]
    }
   ],
   "source": [
    "# example of output \n",
    "rank('china')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pseudo-truth set using first 5 words \n",
    "# Because I don't have a turth set I will generate a pseudo one by pulling terms from the documents - this is far from perfect\n",
    "     # as it may not approximate well peoples actual queries but it will serve well to build the ML architecture \n",
    "\n",
    "df_truth = pd.DataFrame()\n",
    "\n",
    "for doc in plottest:\n",
    "    first_five = doc[0:5]\n",
    "    test_sentence = ' '.join(first_five)\n",
    "    result = search(test_sentence)\n",
    "    df_temp = pd.DataFrame([result])\n",
    "    df_truth= pd.concat([df_truth, df_temp])\n",
    "\n",
    "df_truth['truth'] = range(0,len(plottest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create another psuedo-truth set using random 3 word sequence from docs\n",
    "\n",
    "df_truth1 = pd.DataFrame()\n",
    "seqlen = 3\n",
    "\n",
    "for doc in plottest:\n",
    "    try:\n",
    "        start = random.randint(0,(len(doc)-seqlen))\n",
    "        random_seq = doc[start:start+seqlen]\n",
    "        test_sentence = ' '.join(random_seq)\n",
    "    except:\n",
    "        test_sentence = doc[0]\n",
    "    result = search(test_sentence)\n",
    "    df_temp = pd.DataFrame([result])\n",
    "    df_truth1= pd.concat([df_truth1, df_temp])\n",
    "\n",
    "df_truth1['truth'] = range(0,len(plottest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create another psuedo-truth set using different random 4 word sequence from docs\n",
    "\n",
    "df_truth2 = pd.DataFrame()\n",
    "seqlen = 4\n",
    "\n",
    "for doc in plottest:\n",
    "    try:\n",
    "        start = random.randint(0,(len(doc)-seqlen))\n",
    "        random_seq = doc[start:start+seqlen]\n",
    "        test_sentence = ' '.join(random_seq)\n",
    "    except:\n",
    "        test_sentence = doc[0]\n",
    "    result = search(test_sentence)\n",
    "    df_temp = pd.DataFrame([result])\n",
    "    df_truth2= pd.concat([df_truth2, df_temp])\n",
    "\n",
    "df_truth2['truth'] = range(0,len(plottest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create another psuedo-truth set using different random 2 word sequence from docs\n",
    "\n",
    "df_truth3 = pd.DataFrame()\n",
    "seqlen = 2\n",
    "\n",
    "for doc in plottest:\n",
    "    try:\n",
    "        start = random.randint(0,(len(doc)-seqlen))\n",
    "        random_seq = doc[start:start+seqlen]\n",
    "        test_sentence = ' '.join(random_seq)\n",
    "    except:\n",
    "        test_sentence = doc[0]\n",
    "    result = search(test_sentence)\n",
    "    df_temp = pd.DataFrame([result])\n",
    "    df_truth3= pd.concat([df_truth3, df_temp])\n",
    "\n",
    "df_truth3['truth'] = range(0,len(plottest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the truth sets and save to disk \n",
    "truth_set = pd.concat([df_truth,df_truth1,df_truth2,df_truth3])\n",
    "truth_set.columns = ['search term', 'actual_words_searched','num_occur','percentage_of_terms','td-idf','word_order','truth']\n",
    "truth_set.to_csv(\"truth_set_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>search term</th>\n",
       "      <th>actual_words_searched</th>\n",
       "      <th>num_occur</th>\n",
       "      <th>percentage_of_terms</th>\n",
       "      <th>td-idf</th>\n",
       "      <th>word_order</th>\n",
       "      <th>truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>asian exporters fear damage usjapan</td>\n",
       "      <td>[asian, exporters, fear, damage, usjapan]</td>\n",
       "      <td>[(569, 4), (453, 3), (138, 2), (276, 2), (582,...</td>\n",
       "      <td>[(0, 1.0), (761, 0.4), (111, 0.4), (138, 0.2),...</td>\n",
       "      <td>[(586, 0.3862756764125228), (594, 0.3862756764...</td>\n",
       "      <td>[(0, 4), (761, 0), (111, 0)]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>china daily says vermin eat</td>\n",
       "      <td>[china, daily, says, vermin, eat]</td>\n",
       "      <td>[(183, 5), (40, 4), (569, 3), (710, 3), (342, ...</td>\n",
       "      <td>[(1, 1.0), (13, 0.4), (14, 0.4), (281, 0.4), (...</td>\n",
       "      <td>[(675, 0.5095658223243495), (135, 0.4367707048...</td>\n",
       "      <td>[(1, 5), (293, 1), (720, 1), (721, 1), (736, 0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>japan revise longterm energy demand</td>\n",
       "      <td>[japan, revise, longterm, energy, demand]</td>\n",
       "      <td>[(728, 10), (0, 9), (282, 8), (691, 8), (272, ...</td>\n",
       "      <td>[(2, 1.0), (14, 0.4), (279, 0.4), (285, 0.4), ...</td>\n",
       "      <td>[(684, 0.29388161853201494), (919, 0.286868066...</td>\n",
       "      <td>[(2, 7), (701, 0), (663, 0), (681, 0), (695, 0...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thai trade deficit widens first</td>\n",
       "      <td>[thai, trade, deficit, widens, first]</td>\n",
       "      <td>[(273, 21), (544, 10), (761, 8), (858, 7), (22...</td>\n",
       "      <td>[(701, 1.2), (3, 1.0), (923, 0.8), (18, 0.6), ...</td>\n",
       "      <td>[(552, 0.36954211323937414), (223, 0.247281273...</td>\n",
       "      <td>[(273, 6), (3, 5), (384, 2), (385, 2), (291, 2...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>indonesia sees cpo price rising</td>\n",
       "      <td>[indonesia, sees, cpo, price, rising]</td>\n",
       "      <td>[(572, 19), (639, 8), (108, 7), (148, 7), (736...</td>\n",
       "      <td>[(4, 1.0), (294, 0.6), (6, 0.4), (311, 0.4), (...</td>\n",
       "      <td>[(212, 0.40873824949762244), (366, 0.408738249...</td>\n",
       "      <td>[(4, 4), (6, 0), (279, 0), (792, 0), (285, 0),...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>australian foreign ship ban ends</td>\n",
       "      <td>[australian, foreign, ship, ban, ends]</td>\n",
       "      <td>[(510, 8), (408, 6), (18, 5), (23, 5), (621, 5...</td>\n",
       "      <td>[(5, 1.0), (61, 1.0), (0, 0.4), (31, 0.4), (32...</td>\n",
       "      <td>[(510, 0.27446283551031375), (229, 0.131136680...</td>\n",
       "      <td>[(5, 4), (61, 4), (0, 0), (32, 0), (36, 0), (7...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>indonesian commodity exchange may expand</td>\n",
       "      <td>[indonesian, commodity, exchange, may, expand]</td>\n",
       "      <td>[(183, 11), (596, 5), (271, 3), (290, 3), (382...</td>\n",
       "      <td>[(6, 1.0), (735, 0.6), (9, 0.6), (123, 0.4), (...</td>\n",
       "      <td>[(659, 0.24078345037131432), (507, 0.197605473...</td>\n",
       "      <td>[(6, 6), (663, 1), (0, 0), (384, 0), (387, 0),...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sri lanka gets usda approval</td>\n",
       "      <td>[sri, lanka, gets, usda, approval]</td>\n",
       "      <td>[(584, 7), (814, 5), (569, 4), (208, 3), (561,...</td>\n",
       "      <td>[(7, 1.0), (640, 0.6), (377, 0.4), (701, 0.4),...</td>\n",
       "      <td>[(549, 0.26365820837225185), (550, 0.241686691...</td>\n",
       "      <td>[(7, 4), (377, 2), (640, 1), (724, 0), (701, 0)]</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>western mining open new gold</td>\n",
       "      <td>[western, mining, open, new, gold]</td>\n",
       "      <td>[(997, 6), (20, 5), (569, 5), (384, 5), (797, ...</td>\n",
       "      <td>[(8, 1.0), (701, 0.8), (724, 0.8), (20, 0.6), ...</td>\n",
       "      <td>[(972, 0.38161201272063366), (983, 0.319308010...</td>\n",
       "      <td>[(8, 5), (716, 2), (257, 1), (12, 1), (276, 1)...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sumitomo bank aims quick recovery</td>\n",
       "      <td>[sumitomo, bank, aims, quick, recovery]</td>\n",
       "      <td>[(118, 6), (336, 6), (374, 6), (691, 6), (798,...</td>\n",
       "      <td>[(9, 1.0), (32, 0.4), (33, 0.4), (285, 0.4), (...</td>\n",
       "      <td>[(684, 0.22331565055000002), (709, 0.200984085...</td>\n",
       "      <td>[(9, 6), (32, 0), (33, 0), (322, 0), (384, 0),...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                search term  \\\n",
       "0       asian exporters fear damage usjapan   \n",
       "0               china daily says vermin eat   \n",
       "0       japan revise longterm energy demand   \n",
       "0           thai trade deficit widens first   \n",
       "0           indonesia sees cpo price rising   \n",
       "0          australian foreign ship ban ends   \n",
       "0  indonesian commodity exchange may expand   \n",
       "0              sri lanka gets usda approval   \n",
       "0              western mining open new gold   \n",
       "0         sumitomo bank aims quick recovery   \n",
       "\n",
       "                            actual_words_searched  \\\n",
       "0       [asian, exporters, fear, damage, usjapan]   \n",
       "0               [china, daily, says, vermin, eat]   \n",
       "0       [japan, revise, longterm, energy, demand]   \n",
       "0           [thai, trade, deficit, widens, first]   \n",
       "0           [indonesia, sees, cpo, price, rising]   \n",
       "0          [australian, foreign, ship, ban, ends]   \n",
       "0  [indonesian, commodity, exchange, may, expand]   \n",
       "0              [sri, lanka, gets, usda, approval]   \n",
       "0              [western, mining, open, new, gold]   \n",
       "0         [sumitomo, bank, aims, quick, recovery]   \n",
       "\n",
       "                                           num_occur  \\\n",
       "0  [(569, 4), (453, 3), (138, 2), (276, 2), (582,...   \n",
       "0  [(183, 5), (40, 4), (569, 3), (710, 3), (342, ...   \n",
       "0  [(728, 10), (0, 9), (282, 8), (691, 8), (272, ...   \n",
       "0  [(273, 21), (544, 10), (761, 8), (858, 7), (22...   \n",
       "0  [(572, 19), (639, 8), (108, 7), (148, 7), (736...   \n",
       "0  [(510, 8), (408, 6), (18, 5), (23, 5), (621, 5...   \n",
       "0  [(183, 11), (596, 5), (271, 3), (290, 3), (382...   \n",
       "0  [(584, 7), (814, 5), (569, 4), (208, 3), (561,...   \n",
       "0  [(997, 6), (20, 5), (569, 5), (384, 5), (797, ...   \n",
       "0  [(118, 6), (336, 6), (374, 6), (691, 6), (798,...   \n",
       "\n",
       "                                 percentage_of_terms  \\\n",
       "0  [(0, 1.0), (761, 0.4), (111, 0.4), (138, 0.2),...   \n",
       "0  [(1, 1.0), (13, 0.4), (14, 0.4), (281, 0.4), (...   \n",
       "0  [(2, 1.0), (14, 0.4), (279, 0.4), (285, 0.4), ...   \n",
       "0  [(701, 1.2), (3, 1.0), (923, 0.8), (18, 0.6), ...   \n",
       "0  [(4, 1.0), (294, 0.6), (6, 0.4), (311, 0.4), (...   \n",
       "0  [(5, 1.0), (61, 1.0), (0, 0.4), (31, 0.4), (32...   \n",
       "0  [(6, 1.0), (735, 0.6), (9, 0.6), (123, 0.4), (...   \n",
       "0  [(7, 1.0), (640, 0.6), (377, 0.4), (701, 0.4),...   \n",
       "0  [(8, 1.0), (701, 0.8), (724, 0.8), (20, 0.6), ...   \n",
       "0  [(9, 1.0), (32, 0.4), (33, 0.4), (285, 0.4), (...   \n",
       "\n",
       "                                              td-idf  \\\n",
       "0  [(586, 0.3862756764125228), (594, 0.3862756764...   \n",
       "0  [(675, 0.5095658223243495), (135, 0.4367707048...   \n",
       "0  [(684, 0.29388161853201494), (919, 0.286868066...   \n",
       "0  [(552, 0.36954211323937414), (223, 0.247281273...   \n",
       "0  [(212, 0.40873824949762244), (366, 0.408738249...   \n",
       "0  [(510, 0.27446283551031375), (229, 0.131136680...   \n",
       "0  [(659, 0.24078345037131432), (507, 0.197605473...   \n",
       "0  [(549, 0.26365820837225185), (550, 0.241686691...   \n",
       "0  [(972, 0.38161201272063366), (983, 0.319308010...   \n",
       "0  [(684, 0.22331565055000002), (709, 0.200984085...   \n",
       "\n",
       "                                          word_order  truth  \n",
       "0                       [(0, 4), (761, 0), (111, 0)]      0  \n",
       "0  [(1, 5), (293, 1), (720, 1), (721, 1), (736, 0...      1  \n",
       "0  [(2, 7), (701, 0), (663, 0), (681, 0), (695, 0...      2  \n",
       "0  [(273, 6), (3, 5), (384, 2), (385, 2), (291, 2...      3  \n",
       "0  [(4, 4), (6, 0), (279, 0), (792, 0), (285, 0),...      4  \n",
       "0  [(5, 4), (61, 4), (0, 0), (32, 0), (36, 0), (7...      5  \n",
       "0  [(6, 6), (663, 1), (0, 0), (384, 0), (387, 0),...      6  \n",
       "0   [(7, 4), (377, 2), (640, 1), (724, 0), (701, 0)]      7  \n",
       "0  [(8, 5), (716, 2), (257, 1), (12, 1), (276, 1)...      8  \n",
       "0  [(9, 6), (32, 0), (33, 0), (322, 0), (384, 0),...      9  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truth_set[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>search term</th>\n",
       "      <th>actual_words_searched</th>\n",
       "      <th>num_occur</th>\n",
       "      <th>percentage_of_terms</th>\n",
       "      <th>td-idf</th>\n",
       "      <th>word_order</th>\n",
       "      <th>truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>asian exporters fear damage usjapan</td>\n",
       "      <td>[asian, exporters, fear, damage, usjapan]</td>\n",
       "      <td>[(569, 4), (453, 3), (138, 2), (276, 2), (582,...</td>\n",
       "      <td>[(0, 1.0), (761, 0.4), (111, 0.4), (138, 0.2),...</td>\n",
       "      <td>[(586, 0.3862756764125228), (594, 0.3862756764...</td>\n",
       "      <td>[(0, 4), (761, 0), (111, 0)]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>china daily says vermin eat</td>\n",
       "      <td>[china, daily, says, vermin, eat]</td>\n",
       "      <td>[(183, 5), (40, 4), (569, 3), (710, 3), (342, ...</td>\n",
       "      <td>[(1, 1.0), (13, 0.4), (14, 0.4), (281, 0.4), (...</td>\n",
       "      <td>[(675, 0.5095658223243495), (135, 0.4367707048...</td>\n",
       "      <td>[(1, 5), (293, 1), (720, 1), (721, 1), (736, 0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>japan revise longterm energy demand</td>\n",
       "      <td>[japan, revise, longterm, energy, demand]</td>\n",
       "      <td>[(728, 10), (0, 9), (282, 8), (691, 8), (272, ...</td>\n",
       "      <td>[(2, 1.0), (14, 0.4), (279, 0.4), (285, 0.4), ...</td>\n",
       "      <td>[(684, 0.29388161853201494), (919, 0.286868066...</td>\n",
       "      <td>[(2, 7), (701, 0), (663, 0), (681, 0), (695, 0...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           search term  \\\n",
       "0  asian exporters fear damage usjapan   \n",
       "0          china daily says vermin eat   \n",
       "0  japan revise longterm energy demand   \n",
       "\n",
       "                       actual_words_searched  \\\n",
       "0  [asian, exporters, fear, damage, usjapan]   \n",
       "0          [china, daily, says, vermin, eat]   \n",
       "0  [japan, revise, longterm, energy, demand]   \n",
       "\n",
       "                                           num_occur  \\\n",
       "0  [(569, 4), (453, 3), (138, 2), (276, 2), (582,...   \n",
       "0  [(183, 5), (40, 4), (569, 3), (710, 3), (342, ...   \n",
       "0  [(728, 10), (0, 9), (282, 8), (691, 8), (272, ...   \n",
       "\n",
       "                                 percentage_of_terms  \\\n",
       "0  [(0, 1.0), (761, 0.4), (111, 0.4), (138, 0.2),...   \n",
       "0  [(1, 1.0), (13, 0.4), (14, 0.4), (281, 0.4), (...   \n",
       "0  [(2, 1.0), (14, 0.4), (279, 0.4), (285, 0.4), ...   \n",
       "\n",
       "                                              td-idf  \\\n",
       "0  [(586, 0.3862756764125228), (594, 0.3862756764...   \n",
       "0  [(675, 0.5095658223243495), (135, 0.4367707048...   \n",
       "0  [(684, 0.29388161853201494), (919, 0.286868066...   \n",
       "\n",
       "                                          word_order  truth  \n",
       "0                       [(0, 4), (761, 0), (111, 0)]      0  \n",
       "0  [(1, 5), (293, 1), (720, 1), (721, 1), (736, 0...      1  \n",
       "0  [(2, 7), (701, 0), (663, 0), (681, 0), (695, 0...      2  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truth_set\n",
    "test_set = truth_set[0:3]\n",
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>search term</th>\n",
       "      <th>actual_words_searched</th>\n",
       "      <th>num_occur</th>\n",
       "      <th>percentage_of_terms</th>\n",
       "      <th>td-idf</th>\n",
       "      <th>word_order</th>\n",
       "      <th>(num_occur, index, 0)</th>\n",
       "      <th>(num_occur, score, 0)</th>\n",
       "      <th>(num_occur, index, 1)</th>\n",
       "      <th>(num_occur, score, 1)</th>\n",
       "      <th>...</th>\n",
       "      <th>(word_order, score, 0)</th>\n",
       "      <th>(word_order, index, 1)</th>\n",
       "      <th>(word_order, score, 1)</th>\n",
       "      <th>(word_order, index, 2)</th>\n",
       "      <th>(word_order, score, 2)</th>\n",
       "      <th>truth</th>\n",
       "      <th>(word_order, index, 3)</th>\n",
       "      <th>(word_order, score, 3)</th>\n",
       "      <th>(word_order, index, 4)</th>\n",
       "      <th>(word_order, score, 4)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>china daily says vermin eat</td>\n",
       "      <td>[china, daily, says, vermin, eat]</td>\n",
       "      <td>[(183, 5), (40, 4), (569, 3), (710, 3), (342, ...</td>\n",
       "      <td>[(1, 1.0), (13, 0.4), (14, 0.4), (281, 0.4), (...</td>\n",
       "      <td>[(675, 0.5095658223243495), (135, 0.4367707048...</td>\n",
       "      <td>[(1, 5), (293, 1), (720, 1), (721, 1), (736, 0...</td>\n",
       "      <td>183</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>293.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>720.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>721.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>736.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>japan revise longterm energy demand</td>\n",
       "      <td>[japan, revise, longterm, energy, demand]</td>\n",
       "      <td>[(728, 10), (0, 9), (282, 8), (691, 8), (272, ...</td>\n",
       "      <td>[(2, 1.0), (14, 0.4), (279, 0.4), (285, 0.4), ...</td>\n",
       "      <td>[(684, 0.29388161853201494), (919, 0.286868066...</td>\n",
       "      <td>[(2, 7), (701, 0), (663, 0), (681, 0), (695, 0...</td>\n",
       "      <td>728</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>701.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>663.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>681.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>695.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thai trade deficit widens first</td>\n",
       "      <td>[thai, trade, deficit, widens, first]</td>\n",
       "      <td>[(273, 21), (544, 10), (761, 8), (858, 7), (22...</td>\n",
       "      <td>[(701, 1.2), (3, 1.0), (923, 0.8), (18, 0.6), ...</td>\n",
       "      <td>[(552, 0.36954211323937414), (223, 0.247281273...</td>\n",
       "      <td>[(273, 6), (3, 5), (384, 2), (385, 2), (291, 2...</td>\n",
       "      <td>273</td>\n",
       "      <td>21</td>\n",
       "      <td>544</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>385.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>291.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>indonesia sees cpo price rising</td>\n",
       "      <td>[indonesia, sees, cpo, price, rising]</td>\n",
       "      <td>[(572, 19), (639, 8), (108, 7), (148, 7), (736...</td>\n",
       "      <td>[(4, 1.0), (294, 0.6), (6, 0.4), (311, 0.4), (...</td>\n",
       "      <td>[(212, 0.40873824949762244), (366, 0.408738249...</td>\n",
       "      <td>[(4, 4), (6, 0), (279, 0), (792, 0), (285, 0),...</td>\n",
       "      <td>572</td>\n",
       "      <td>19</td>\n",
       "      <td>639</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>279.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>792.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>australian foreign ship ban ends</td>\n",
       "      <td>[australian, foreign, ship, ban, ends]</td>\n",
       "      <td>[(510, 8), (408, 6), (18, 5), (23, 5), (621, 5...</td>\n",
       "      <td>[(5, 1.0), (61, 1.0), (0, 0.4), (31, 0.4), (32...</td>\n",
       "      <td>[(510, 0.27446283551031375), (229, 0.131136680...</td>\n",
       "      <td>[(5, 4), (61, 4), (0, 0), (32, 0), (36, 0), (7...</td>\n",
       "      <td>510</td>\n",
       "      <td>8</td>\n",
       "      <td>408</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>61.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           search term  \\\n",
       "0          china daily says vermin eat   \n",
       "0  japan revise longterm energy demand   \n",
       "0      thai trade deficit widens first   \n",
       "0      indonesia sees cpo price rising   \n",
       "0     australian foreign ship ban ends   \n",
       "\n",
       "                       actual_words_searched  \\\n",
       "0          [china, daily, says, vermin, eat]   \n",
       "0  [japan, revise, longterm, energy, demand]   \n",
       "0      [thai, trade, deficit, widens, first]   \n",
       "0      [indonesia, sees, cpo, price, rising]   \n",
       "0     [australian, foreign, ship, ban, ends]   \n",
       "\n",
       "                                           num_occur  \\\n",
       "0  [(183, 5), (40, 4), (569, 3), (710, 3), (342, ...   \n",
       "0  [(728, 10), (0, 9), (282, 8), (691, 8), (272, ...   \n",
       "0  [(273, 21), (544, 10), (761, 8), (858, 7), (22...   \n",
       "0  [(572, 19), (639, 8), (108, 7), (148, 7), (736...   \n",
       "0  [(510, 8), (408, 6), (18, 5), (23, 5), (621, 5...   \n",
       "\n",
       "                                 percentage_of_terms  \\\n",
       "0  [(1, 1.0), (13, 0.4), (14, 0.4), (281, 0.4), (...   \n",
       "0  [(2, 1.0), (14, 0.4), (279, 0.4), (285, 0.4), ...   \n",
       "0  [(701, 1.2), (3, 1.0), (923, 0.8), (18, 0.6), ...   \n",
       "0  [(4, 1.0), (294, 0.6), (6, 0.4), (311, 0.4), (...   \n",
       "0  [(5, 1.0), (61, 1.0), (0, 0.4), (31, 0.4), (32...   \n",
       "\n",
       "                                              td-idf  \\\n",
       "0  [(675, 0.5095658223243495), (135, 0.4367707048...   \n",
       "0  [(684, 0.29388161853201494), (919, 0.286868066...   \n",
       "0  [(552, 0.36954211323937414), (223, 0.247281273...   \n",
       "0  [(212, 0.40873824949762244), (366, 0.408738249...   \n",
       "0  [(510, 0.27446283551031375), (229, 0.131136680...   \n",
       "\n",
       "                                          word_order  (num_occur, index, 0)  \\\n",
       "0  [(1, 5), (293, 1), (720, 1), (721, 1), (736, 0...                    183   \n",
       "0  [(2, 7), (701, 0), (663, 0), (681, 0), (695, 0...                    728   \n",
       "0  [(273, 6), (3, 5), (384, 2), (385, 2), (291, 2...                    273   \n",
       "0  [(4, 4), (6, 0), (279, 0), (792, 0), (285, 0),...                    572   \n",
       "0  [(5, 4), (61, 4), (0, 0), (32, 0), (36, 0), (7...                    510   \n",
       "\n",
       "   (num_occur, score, 0)  (num_occur, index, 1)  (num_occur, score, 1)  ...  \\\n",
       "0                      5                     40                      4  ...   \n",
       "0                     10                      0                      9  ...   \n",
       "0                     21                    544                     10  ...   \n",
       "0                     19                    639                      8  ...   \n",
       "0                      8                    408                      6  ...   \n",
       "\n",
       "   (word_order, score, 0)  (word_order, index, 1)  (word_order, score, 1)  \\\n",
       "0                       5                   293.0                     1.0   \n",
       "0                       7                   701.0                     0.0   \n",
       "0                       6                     3.0                     5.0   \n",
       "0                       4                     6.0                     0.0   \n",
       "0                       4                    61.0                     4.0   \n",
       "\n",
       "   (word_order, index, 2)  (word_order, score, 2)  truth  \\\n",
       "0                   720.0                     1.0      1   \n",
       "0                   663.0                     0.0      2   \n",
       "0                   384.0                     2.0      3   \n",
       "0                   279.0                     0.0      4   \n",
       "0                     0.0                     0.0      5   \n",
       "\n",
       "   (word_order, index, 3)  (word_order, score, 3)  (word_order, index, 4)  \\\n",
       "0                   721.0                     1.0                   736.0   \n",
       "0                   681.0                     0.0                   695.0   \n",
       "0                   385.0                     2.0                   291.0   \n",
       "0                   792.0                     0.0                   285.0   \n",
       "0                    32.0                     0.0                    36.0   \n",
       "\n",
       "   (word_order, score, 4)  \n",
       "0                     0.0  \n",
       "0                     0.0  \n",
       "0                     2.0  \n",
       "0                     0.0  \n",
       "0                     0.0  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert to long format for ML \n",
    "# WARNING AGAIN THIS IS A SLOW PROCESS DUE TO RAM ILOC - COULD BE OPTIMISED FOR FASTER PERFORMANCE \n",
    "# BUG When min(maxnum, len(truth_set) <- is a int not a list because of very short variable length)\n",
    "\n",
    "# row is row\n",
    "# column is variable\n",
    "# i is the result \n",
    "\n",
    "final_set =  pd.DataFrame()\n",
    "test_set = truth_set[1:100]\n",
    "maxnum = 5\n",
    "\n",
    "for row in range(0,len(test_set.index)):\n",
    "    test_set = truth_set[1:100]\n",
    "    for col in range(2,6):\n",
    "        for i in range(0,min(maxnum,len(truth_set.iloc[row][col]))):\n",
    "            x = pd.DataFrame([truth_set.iloc[row][col][i]])\n",
    "            x['truth'] = truth_set.iloc[row]['truth']\n",
    "            x.columns = [(str(truth_set.columns[col]),\"index\",i),(str(truth_set.columns[col]),\"score\",i),'truth']\n",
    "            test_set = test_set.merge(x,on='truth')\n",
    "    final_set = pd.concat([final_set,test_set])\n",
    "        \n",
    "final_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_set.to_csv(\"ML_set_100.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\flori\\AppData\\Local\\Temp\\ipykernel_4900\\58453081.py:1: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  final_set2 = final_set.drop(['actual_words_searched','num_occur','percentage_of_terms','search term','td-idf','word_order'], 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(num_occur, index, 0)</th>\n",
       "      <th>(num_occur, score, 0)</th>\n",
       "      <th>(num_occur, index, 1)</th>\n",
       "      <th>(num_occur, score, 1)</th>\n",
       "      <th>(num_occur, index, 2)</th>\n",
       "      <th>(num_occur, score, 2)</th>\n",
       "      <th>(num_occur, index, 3)</th>\n",
       "      <th>(num_occur, score, 3)</th>\n",
       "      <th>(num_occur, index, 4)</th>\n",
       "      <th>(num_occur, score, 4)</th>\n",
       "      <th>...</th>\n",
       "      <th>(word_order, score, 0)</th>\n",
       "      <th>(word_order, index, 1)</th>\n",
       "      <th>(word_order, score, 1)</th>\n",
       "      <th>(word_order, index, 2)</th>\n",
       "      <th>(word_order, score, 2)</th>\n",
       "      <th>truth</th>\n",
       "      <th>(word_order, index, 3)</th>\n",
       "      <th>(word_order, score, 3)</th>\n",
       "      <th>(word_order, index, 4)</th>\n",
       "      <th>(word_order, score, 4)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>183</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>569</td>\n",
       "      <td>3</td>\n",
       "      <td>710</td>\n",
       "      <td>3</td>\n",
       "      <td>342</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>293.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>720.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>721.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>736.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>728</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>282</td>\n",
       "      <td>8</td>\n",
       "      <td>691</td>\n",
       "      <td>8</td>\n",
       "      <td>272</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>701.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>663.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>681.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>695.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>273</td>\n",
       "      <td>21</td>\n",
       "      <td>544</td>\n",
       "      <td>10</td>\n",
       "      <td>761</td>\n",
       "      <td>8</td>\n",
       "      <td>858</td>\n",
       "      <td>7</td>\n",
       "      <td>224</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>385.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>291.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>572</td>\n",
       "      <td>19</td>\n",
       "      <td>639</td>\n",
       "      <td>8</td>\n",
       "      <td>108</td>\n",
       "      <td>7</td>\n",
       "      <td>148</td>\n",
       "      <td>7</td>\n",
       "      <td>736</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>279.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>792.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>510</td>\n",
       "      <td>8</td>\n",
       "      <td>408</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>621</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>61.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   (num_occur, index, 0)  (num_occur, score, 0)  (num_occur, index, 1)  \\\n",
       "0                    183                      5                     40   \n",
       "0                    728                     10                      0   \n",
       "0                    273                     21                    544   \n",
       "0                    572                     19                    639   \n",
       "0                    510                      8                    408   \n",
       "\n",
       "   (num_occur, score, 1)  (num_occur, index, 2)  (num_occur, score, 2)  \\\n",
       "0                      4                    569                      3   \n",
       "0                      9                    282                      8   \n",
       "0                     10                    761                      8   \n",
       "0                      8                    108                      7   \n",
       "0                      6                     18                      5   \n",
       "\n",
       "   (num_occur, index, 3)  (num_occur, score, 3)  (num_occur, index, 4)  \\\n",
       "0                    710                      3                    342   \n",
       "0                    691                      8                    272   \n",
       "0                    858                      7                    224   \n",
       "0                    148                      7                    736   \n",
       "0                     23                      5                    621   \n",
       "\n",
       "   (num_occur, score, 4)  ...  (word_order, score, 0)  (word_order, index, 1)  \\\n",
       "0                      2  ...                       5                   293.0   \n",
       "0                      8  ...                       7                   701.0   \n",
       "0                      6  ...                       6                     3.0   \n",
       "0                      6  ...                       4                     6.0   \n",
       "0                      5  ...                       4                    61.0   \n",
       "\n",
       "   (word_order, score, 1)  (word_order, index, 2)  (word_order, score, 2)  \\\n",
       "0                     1.0                   720.0                     1.0   \n",
       "0                     0.0                   663.0                     0.0   \n",
       "0                     5.0                   384.0                     2.0   \n",
       "0                     0.0                   279.0                     0.0   \n",
       "0                     4.0                     0.0                     0.0   \n",
       "\n",
       "   truth  (word_order, index, 3)  (word_order, score, 3)  \\\n",
       "0      1                   721.0                     1.0   \n",
       "0      2                   681.0                     0.0   \n",
       "0      3                   385.0                     2.0   \n",
       "0      4                   792.0                     0.0   \n",
       "0      5                    32.0                     0.0   \n",
       "\n",
       "   (word_order, index, 4)  (word_order, score, 4)  \n",
       "0                   736.0                     0.0  \n",
       "0                   695.0                     0.0  \n",
       "0                   291.0                     2.0  \n",
       "0                   285.0                     0.0  \n",
       "0                    36.0                     0.0  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_set2 = final_set.drop(['actual_words_searched','num_occur','percentage_of_terms','search term','td-idf','word_order'], 1)\n",
    "final_set2.to_csv(\"ML_set_100_3.csv\")\n",
    "final_set2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(num_occur, index, 0)</th>\n",
       "      <th>(num_occur, score, 0)</th>\n",
       "      <th>(num_occur, index, 1)</th>\n",
       "      <th>(num_occur, score, 1)</th>\n",
       "      <th>(num_occur, index, 2)</th>\n",
       "      <th>(num_occur, score, 2)</th>\n",
       "      <th>(num_occur, index, 3)</th>\n",
       "      <th>(num_occur, score, 3)</th>\n",
       "      <th>(num_occur, index, 4)</th>\n",
       "      <th>(num_occur, score, 4)</th>\n",
       "      <th>...</th>\n",
       "      <th>(word_order, score, 0)</th>\n",
       "      <th>(word_order, index, 1)</th>\n",
       "      <th>(word_order, score, 1)</th>\n",
       "      <th>(word_order, index, 2)</th>\n",
       "      <th>(word_order, score, 2)</th>\n",
       "      <th>truth</th>\n",
       "      <th>(word_order, index, 3)</th>\n",
       "      <th>(word_order, score, 3)</th>\n",
       "      <th>(word_order, index, 4)</th>\n",
       "      <th>(word_order, score, 4)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>183</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>569</td>\n",
       "      <td>3</td>\n",
       "      <td>710</td>\n",
       "      <td>3</td>\n",
       "      <td>342</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>293.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>720.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>721.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>736.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>728</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>282</td>\n",
       "      <td>8</td>\n",
       "      <td>691</td>\n",
       "      <td>8</td>\n",
       "      <td>272</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>701.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>663.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>681.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>695.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>273</td>\n",
       "      <td>21</td>\n",
       "      <td>544</td>\n",
       "      <td>10</td>\n",
       "      <td>761</td>\n",
       "      <td>8</td>\n",
       "      <td>858</td>\n",
       "      <td>7</td>\n",
       "      <td>224</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>385.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>291.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>572</td>\n",
       "      <td>19</td>\n",
       "      <td>639</td>\n",
       "      <td>8</td>\n",
       "      <td>108</td>\n",
       "      <td>7</td>\n",
       "      <td>148</td>\n",
       "      <td>7</td>\n",
       "      <td>736</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>279.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>792.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>510</td>\n",
       "      <td>8</td>\n",
       "      <td>408</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>621</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>61.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>183</td>\n",
       "      <td>11</td>\n",
       "      <td>596</td>\n",
       "      <td>5</td>\n",
       "      <td>271</td>\n",
       "      <td>3</td>\n",
       "      <td>290</td>\n",
       "      <td>3</td>\n",
       "      <td>382</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>663.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>384.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>387.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>584</td>\n",
       "      <td>7</td>\n",
       "      <td>814</td>\n",
       "      <td>5</td>\n",
       "      <td>569</td>\n",
       "      <td>4</td>\n",
       "      <td>208</td>\n",
       "      <td>3</td>\n",
       "      <td>561</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>377.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>724.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>701.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>997</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>569</td>\n",
       "      <td>5</td>\n",
       "      <td>384</td>\n",
       "      <td>5</td>\n",
       "      <td>797</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>716.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>257.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>118</td>\n",
       "      <td>6</td>\n",
       "      <td>336</td>\n",
       "      <td>6</td>\n",
       "      <td>374</td>\n",
       "      <td>6</td>\n",
       "      <td>691</td>\n",
       "      <td>6</td>\n",
       "      <td>798</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>322.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>148</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "      <td>532</td>\n",
       "      <td>4</td>\n",
       "      <td>311</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>281.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows  41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   (num_occur, index, 0)  (num_occur, score, 0)  (num_occur, index, 1)  \\\n",
       "0                    183                      5                     40   \n",
       "0                    728                     10                      0   \n",
       "0                    273                     21                    544   \n",
       "0                    572                     19                    639   \n",
       "0                    510                      8                    408   \n",
       "0                    183                     11                    596   \n",
       "0                    584                      7                    814   \n",
       "0                    997                      6                     20   \n",
       "0                    118                      6                    336   \n",
       "0                    148                      5                      4   \n",
       "\n",
       "   (num_occur, score, 1)  (num_occur, index, 2)  (num_occur, score, 2)  \\\n",
       "0                      4                    569                      3   \n",
       "0                      9                    282                      8   \n",
       "0                     10                    761                      8   \n",
       "0                      8                    108                      7   \n",
       "0                      6                     18                      5   \n",
       "0                      5                    271                      3   \n",
       "0                      5                    569                      4   \n",
       "0                      5                    569                      5   \n",
       "0                      6                    374                      6   \n",
       "0                      4                     26                      4   \n",
       "\n",
       "   (num_occur, index, 3)  (num_occur, score, 3)  (num_occur, index, 4)  \\\n",
       "0                    710                      3                    342   \n",
       "0                    691                      8                    272   \n",
       "0                    858                      7                    224   \n",
       "0                    148                      7                    736   \n",
       "0                     23                      5                    621   \n",
       "0                    290                      3                    382   \n",
       "0                    208                      3                    561   \n",
       "0                    384                      5                    797   \n",
       "0                    691                      6                    798   \n",
       "0                    532                      4                    311   \n",
       "\n",
       "   (num_occur, score, 4)  ...  (word_order, score, 0)  (word_order, index, 1)  \\\n",
       "0                      2  ...                       5                   293.0   \n",
       "0                      8  ...                       7                   701.0   \n",
       "0                      6  ...                       6                     3.0   \n",
       "0                      6  ...                       4                     6.0   \n",
       "0                      5  ...                       4                    61.0   \n",
       "0                      3  ...                       6                   663.0   \n",
       "0                      3  ...                       4                   377.0   \n",
       "0                      5  ...                       5                   716.0   \n",
       "0                      6  ...                       6                    32.0   \n",
       "0                      3  ...                       4                   281.0   \n",
       "\n",
       "   (word_order, score, 1)  (word_order, index, 2)  (word_order, score, 2)  \\\n",
       "0                     1.0                   720.0                     1.0   \n",
       "0                     0.0                   663.0                     0.0   \n",
       "0                     5.0                   384.0                     2.0   \n",
       "0                     0.0                   279.0                     0.0   \n",
       "0                     4.0                     0.0                     0.0   \n",
       "0                     1.0                     0.0                     0.0   \n",
       "0                     2.0                   640.0                     1.0   \n",
       "0                     2.0                   257.0                     1.0   \n",
       "0                     0.0                    33.0                     0.0   \n",
       "0                     0.0                     NaN                     NaN   \n",
       "\n",
       "   truth  (word_order, index, 3)  (word_order, score, 3)  \\\n",
       "0      1                   721.0                     1.0   \n",
       "0      2                   681.0                     0.0   \n",
       "0      3                   385.0                     2.0   \n",
       "0      4                   792.0                     0.0   \n",
       "0      5                    32.0                     0.0   \n",
       "0      6                   384.0                     0.0   \n",
       "0      7                   724.0                     0.0   \n",
       "0      8                    12.0                     1.0   \n",
       "0      9                   322.0                     0.0   \n",
       "0     10                     NaN                     NaN   \n",
       "\n",
       "   (word_order, index, 4)  (word_order, score, 4)  \n",
       "0                   736.0                     0.0  \n",
       "0                   695.0                     0.0  \n",
       "0                   291.0                     2.0  \n",
       "0                   285.0                     0.0  \n",
       "0                    36.0                     0.0  \n",
       "0                   387.0                     0.0  \n",
       "0                   701.0                     0.0  \n",
       "0                   276.0                     1.0  \n",
       "0                   384.0                     0.0  \n",
       "0                     NaN                     NaN  \n",
       "\n",
       "[10 rows x 41 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_set3 = final_set2\n",
    "final_set3[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries \n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as sm\n",
    "import statsmodels.api as sma\n",
    "from statsmodels.tools.eval_measures import mse\n",
    "from statsmodels.tools.tools import add_constant\n",
    "\n",
    "from sklearn import linear_model, model_selection, feature_selection,preprocessing\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\flori\\AppData\\Local\\Temp\\ipykernel_4900\\2565305869.py:2: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  final_set3 = final_set3.drop(['truth'], 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(num_occur, index, 0)</th>\n",
       "      <th>(num_occur, score, 0)</th>\n",
       "      <th>(num_occur, index, 1)</th>\n",
       "      <th>(num_occur, score, 1)</th>\n",
       "      <th>(num_occur, index, 2)</th>\n",
       "      <th>(num_occur, score, 2)</th>\n",
       "      <th>(num_occur, index, 3)</th>\n",
       "      <th>(num_occur, score, 3)</th>\n",
       "      <th>(num_occur, index, 4)</th>\n",
       "      <th>(num_occur, score, 4)</th>\n",
       "      <th>...</th>\n",
       "      <th>(word_order, score, 0)</th>\n",
       "      <th>(word_order, index, 1)</th>\n",
       "      <th>(word_order, score, 1)</th>\n",
       "      <th>(word_order, index, 2)</th>\n",
       "      <th>(word_order, score, 2)</th>\n",
       "      <th>(word_order, index, 3)</th>\n",
       "      <th>(word_order, score, 3)</th>\n",
       "      <th>(word_order, index, 4)</th>\n",
       "      <th>(word_order, score, 4)</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>183</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>569</td>\n",
       "      <td>3</td>\n",
       "      <td>710</td>\n",
       "      <td>3</td>\n",
       "      <td>342</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>293.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>720.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>721.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>736.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>728</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>282</td>\n",
       "      <td>8</td>\n",
       "      <td>691</td>\n",
       "      <td>8</td>\n",
       "      <td>272</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>701.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>663.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>681.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>695.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>273</td>\n",
       "      <td>21</td>\n",
       "      <td>544</td>\n",
       "      <td>10</td>\n",
       "      <td>761</td>\n",
       "      <td>8</td>\n",
       "      <td>858</td>\n",
       "      <td>7</td>\n",
       "      <td>224</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>385.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>291.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>572</td>\n",
       "      <td>19</td>\n",
       "      <td>639</td>\n",
       "      <td>8</td>\n",
       "      <td>108</td>\n",
       "      <td>7</td>\n",
       "      <td>148</td>\n",
       "      <td>7</td>\n",
       "      <td>736</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>279.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>792.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>510</td>\n",
       "      <td>8</td>\n",
       "      <td>408</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>621</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>61.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>259</td>\n",
       "      <td>4</td>\n",
       "      <td>963</td>\n",
       "      <td>4</td>\n",
       "      <td>633</td>\n",
       "      <td>3</td>\n",
       "      <td>900</td>\n",
       "      <td>3</td>\n",
       "      <td>920</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>793.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>724.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>259</td>\n",
       "      <td>4</td>\n",
       "      <td>963</td>\n",
       "      <td>4</td>\n",
       "      <td>633</td>\n",
       "      <td>3</td>\n",
       "      <td>900</td>\n",
       "      <td>3</td>\n",
       "      <td>920</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>95.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>724.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>502.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>700</td>\n",
       "      <td>12</td>\n",
       "      <td>494</td>\n",
       "      <td>7</td>\n",
       "      <td>296</td>\n",
       "      <td>6</td>\n",
       "      <td>525</td>\n",
       "      <td>6</td>\n",
       "      <td>476</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>337.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>166</td>\n",
       "      <td>7</td>\n",
       "      <td>444</td>\n",
       "      <td>5</td>\n",
       "      <td>259</td>\n",
       "      <td>4</td>\n",
       "      <td>963</td>\n",
       "      <td>4</td>\n",
       "      <td>106</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>141.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>984</td>\n",
       "      <td>13</td>\n",
       "      <td>700</td>\n",
       "      <td>12</td>\n",
       "      <td>96</td>\n",
       "      <td>8</td>\n",
       "      <td>521</td>\n",
       "      <td>7</td>\n",
       "      <td>494</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>296.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98 rows  41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    (num_occur, index, 0)  (num_occur, score, 0)  (num_occur, index, 1)  \\\n",
       "0                     183                      5                     40   \n",
       "0                     728                     10                      0   \n",
       "0                     273                     21                    544   \n",
       "0                     572                     19                    639   \n",
       "0                     510                      8                    408   \n",
       "..                    ...                    ...                    ...   \n",
       "0                     259                      4                    963   \n",
       "0                     259                      4                    963   \n",
       "0                     700                     12                    494   \n",
       "0                     166                      7                    444   \n",
       "0                     984                     13                    700   \n",
       "\n",
       "    (num_occur, score, 1)  (num_occur, index, 2)  (num_occur, score, 2)  \\\n",
       "0                       4                    569                      3   \n",
       "0                       9                    282                      8   \n",
       "0                      10                    761                      8   \n",
       "0                       8                    108                      7   \n",
       "0                       6                     18                      5   \n",
       "..                    ...                    ...                    ...   \n",
       "0                       4                    633                      3   \n",
       "0                       4                    633                      3   \n",
       "0                       7                    296                      6   \n",
       "0                       5                    259                      4   \n",
       "0                      12                     96                      8   \n",
       "\n",
       "    (num_occur, index, 3)  (num_occur, score, 3)  (num_occur, index, 4)  \\\n",
       "0                     710                      3                    342   \n",
       "0                     691                      8                    272   \n",
       "0                     858                      7                    224   \n",
       "0                     148                      7                    736   \n",
       "0                      23                      5                    621   \n",
       "..                    ...                    ...                    ...   \n",
       "0                     900                      3                    920   \n",
       "0                     900                      3                    920   \n",
       "0                     525                      6                    476   \n",
       "0                     963                      4                    106   \n",
       "0                     521                      7                    494   \n",
       "\n",
       "    (num_occur, score, 4)  ...  (word_order, score, 0)  \\\n",
       "0                       2  ...                       5   \n",
       "0                       8  ...                       7   \n",
       "0                       6  ...                       6   \n",
       "0                       6  ...                       4   \n",
       "0                       5  ...                       4   \n",
       "..                    ...  ...                     ...   \n",
       "0                       3  ...                       8   \n",
       "0                       3  ...                       4   \n",
       "0                       4  ...                       7   \n",
       "0                       4  ...                       8   \n",
       "0                       7  ...                       5   \n",
       "\n",
       "    (word_order, index, 1)  (word_order, score, 1)  (word_order, index, 2)  \\\n",
       "0                    293.0                     1.0                   720.0   \n",
       "0                    701.0                     0.0                   663.0   \n",
       "0                      3.0                     5.0                   384.0   \n",
       "0                      6.0                     0.0                   279.0   \n",
       "0                     61.0                     4.0                     0.0   \n",
       "..                     ...                     ...                     ...   \n",
       "0                    793.0                     2.0                    95.0   \n",
       "0                     95.0                     4.0                   724.0   \n",
       "0                    337.0                     1.0                     NaN   \n",
       "0                    141.0                     4.0                   102.0   \n",
       "0                    296.0                     3.0                    48.0   \n",
       "\n",
       "    (word_order, score, 2)  (word_order, index, 3)  (word_order, score, 3)  \\\n",
       "0                      1.0                   721.0                     1.0   \n",
       "0                      0.0                   681.0                     0.0   \n",
       "0                      2.0                   385.0                     2.0   \n",
       "0                      0.0                   792.0                     0.0   \n",
       "0                      0.0                    32.0                     0.0   \n",
       "..                     ...                     ...                     ...   \n",
       "0                      2.0                   195.0                     0.0   \n",
       "0                      0.0                   502.0                     0.0   \n",
       "0                      NaN                     NaN                     NaN   \n",
       "0                      3.0                   195.0                     3.0   \n",
       "0                      3.0                    29.0                     2.0   \n",
       "\n",
       "    (word_order, index, 4)  (word_order, score, 4)   y  \n",
       "0                    736.0                     0.0   1  \n",
       "0                    695.0                     0.0   2  \n",
       "0                    291.0                     2.0   3  \n",
       "0                    285.0                     0.0   4  \n",
       "0                     36.0                     0.0   5  \n",
       "..                     ...                     ...  ..  \n",
       "0                    724.0                     0.0  94  \n",
       "0                      NaN                     NaN  95  \n",
       "0                      NaN                     NaN  96  \n",
       "0                     62.0                     2.0  97  \n",
       "0                     30.0                     1.0  98  \n",
       "\n",
       "[98 rows x 41 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_set3['y'] = final_set3['truth']\n",
    "final_set3 = final_set3.drop(['truth'], 1)\n",
    "final_set3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(num_occur, index, 0)             -0.088007\n",
       "(num_occur, score, 0)             -0.187735\n",
       "(num_occur, index, 1)              0.036880\n",
       "(num_occur, score, 1)             -0.076261\n",
       "(num_occur, index, 2)             -0.063407\n",
       "(num_occur, score, 2)             -0.128061\n",
       "(num_occur, index, 3)             -0.168653\n",
       "(num_occur, score, 3)             -0.159853\n",
       "(num_occur, index, 4)              0.034847\n",
       "(num_occur, score, 4)             -0.144217\n",
       "(percentage_of_terms, index, 0)    0.026640\n",
       "(percentage_of_terms, score, 0)   -0.169683\n",
       "(percentage_of_terms, index, 1)    0.070514\n",
       "(percentage_of_terms, score, 1)   -0.079468\n",
       "(percentage_of_terms, index, 2)   -0.149705\n",
       "(percentage_of_terms, score, 2)   -0.102343\n",
       "(percentage_of_terms, index, 3)   -0.016807\n",
       "(percentage_of_terms, score, 3)    0.019962\n",
       "(percentage_of_terms, index, 4)   -0.045489\n",
       "(percentage_of_terms, score, 4)   -0.002568\n",
       "(td-idf, index, 0)                -0.201462\n",
       "(td-idf, score, 0)                -0.034749\n",
       "(td-idf, index, 1)                -0.196263\n",
       "(td-idf, score, 1)                -0.093650\n",
       "(td-idf, index, 2)                -0.127336\n",
       "(td-idf, score, 2)                -0.059986\n",
       "(td-idf, index, 3)                -0.070057\n",
       "(td-idf, score, 3)                -0.105149\n",
       "(td-idf, index, 4)                -0.017236\n",
       "(td-idf, score, 4)                -0.099558\n",
       "(word_order, index, 0)             0.415397\n",
       "(word_order, score, 0)             0.016328\n",
       "(word_order, index, 1)             0.060298\n",
       "(word_order, score, 1)             0.025704\n",
       "(word_order, index, 2)             0.155283\n",
       "(word_order, score, 2)             0.165187\n",
       "(word_order, index, 3)             0.128043\n",
       "(word_order, score, 3)             0.176349\n",
       "(word_order, index, 4)            -0.023863\n",
       "(word_order, score, 4)             0.205425\n",
       "y                                  1.000000\n",
       "Name: y, dtype: float64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = final_set3\n",
    "data.corr()['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['a'] = data[data.columns[0]]\n",
    "data['b'] = data[data.columns[10]]\n",
    "data['c'] = data[data.columns[20]]\n",
    "data['d'] = data[data.columns[30]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.146</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.099</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   3.124</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 28 Jul 2022</td> <th>  Prob (F-statistic):</th>  <td>0.0198</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>23:47:39</td>     <th>  Log-Likelihood:    </th> <td> -366.49</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    78</td>      <th>  AIC:               </th> <td>   743.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    73</td>      <th>  BIC:               </th> <td>   754.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   50.2844</td> <td>    6.593</td> <td>    7.627</td> <td> 0.000</td> <td>   37.145</td> <td>   63.424</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>a</th>         <td>   -0.0046</td> <td>    0.011</td> <td>   -0.426</td> <td> 0.671</td> <td>   -0.026</td> <td>    0.017</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>b</th>         <td>   -0.0055</td> <td>    0.029</td> <td>   -0.192</td> <td> 0.849</td> <td>   -0.063</td> <td>    0.052</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>c</th>         <td>   -0.0080</td> <td>    0.011</td> <td>   -0.699</td> <td> 0.487</td> <td>   -0.031</td> <td>    0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>d</th>         <td>    0.1036</td> <td>    0.032</td> <td>    3.289</td> <td> 0.002</td> <td>    0.041</td> <td>    0.166</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 6.723</td> <th>  Durbin-Watson:     </th> <td>   2.361</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.035</td> <th>  Jarque-Bera (JB):  </th> <td>   2.885</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.146</td> <th>  Prob(JB):          </th> <td>   0.236</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.104</td> <th>  Cond. No.          </th> <td>1.29e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.29e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.146\n",
       "Model:                            OLS   Adj. R-squared:                  0.099\n",
       "Method:                 Least Squares   F-statistic:                     3.124\n",
       "Date:                Thu, 28 Jul 2022   Prob (F-statistic):             0.0198\n",
       "Time:                        23:47:39   Log-Likelihood:                -366.49\n",
       "No. Observations:                  78   AIC:                             743.0\n",
       "Df Residuals:                      73   BIC:                             754.8\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     50.2844      6.593      7.627      0.000      37.145      63.424\n",
       "a             -0.0046      0.011     -0.426      0.671      -0.026       0.017\n",
       "b             -0.0055      0.029     -0.192      0.849      -0.063       0.052\n",
       "c             -0.0080      0.011     -0.699      0.487      -0.031       0.015\n",
       "d              0.1036      0.032      3.289      0.002       0.041       0.166\n",
       "==============================================================================\n",
       "Omnibus:                        6.723   Durbin-Watson:                   2.361\n",
       "Prob(Omnibus):                  0.035   Jarque-Bera (JB):                2.885\n",
       "Skew:                          -0.146   Prob(JB):                        0.236\n",
       "Kurtosis:                       2.104   Cond. No.                     1.29e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.29e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data\n",
    "\n",
    "train,test = model_selection.train_test_split(X,train_size=0.80)\n",
    "\n",
    "model = sm.ols(formula='y ~ 1 + a + b + c + d', \n",
    "               data=train).fit()\n",
    "\n",
    "modelforout = model \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "fig = sma.graphics.influence_plot(modelforout, ax=ax, criterion=\"cooks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "res = model.resid # residuals\n",
    "fig = sma.qqplot(res)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULT 1 : CHINA CHILE TO BUILD COPPER TUBE PLANT IN CHINA\n",
      "  Chinas stateowned Beijing NonFerrous\n",
      "  Metals Indu ...\n",
      "RESULT 2 : NIPPON STEEL DENIES CHINA SEEKING JAPANESE PLANTS\n",
      "  Nippon Steel Corp ltNSTCT denied local\n",
      "  newspap ...\n",
      "RESULT 3 : CHINA RAISES GRAIN PURCHASE PRICES\n",
      "  China has raised the state purchase\n",
      "  prices of corn rice cotto ...\n",
      "RESULT 4 : CHINA DAILY SAYS VERMIN EAT 712 PCT GRAIN STOCKS\n",
      "  A survey of 19 provinces and seven cities\n",
      "  showe ...\n",
      "RESULT 5 : CHINA SULPHURIRON MINE STARTS PRODUCTION\n",
      "  Chinas largest sulphuriron mine has\n",
      "  started trial produ ...\n"
     ]
    }
   ],
   "source": [
    "term = input(\"search: \")\n",
    "rank(term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULT 1 : Burmah Oil 1986 pretax profit 1059 mln stg vs 796 mln\n",
      "\n",
      "  Burmah Oil 1986 pretax profit 1059 mln stg  ...\n",
      "RESULT 2 : CHINA SULPHURIRON MINE STARTS PRODUCTION\n",
      "  Chinas largest sulphuriron mine has\n",
      "  started trial produ ...\n",
      "RESULT 3 : CSR SAYS IT IS RETAINING NONDELHI GASOIL STAKES\n",
      "  CSR Ltd ltCSRAS said its sale of ltDelhi\n",
      "  Petrole ...\n",
      "RESULT 4 : NET CHANGE IN EXPORT COMMITMENTS  USDA\n",
      "  The US Agriculture Department gave\n",
      "  the net change in expo ...\n",
      "RESULT 5 : OFFER FOR DOME MAY SHORTCIRCUIT ITS DEBT TALKS\n",
      "  A 322 billion dlr offer for Dome\n",
      "  Petroleum Ltd lt ...\n",
      "sorry it was not helpful, try again\n"
     ]
    }
   ],
   "source": [
    "term = input(\"search: \")\n",
    "try:\n",
    "    result = rank(term)\n",
    "    result\n",
    "    feedback = input(\"were these articles helpful?, (Y/N): \")\n",
    "    if feedback == \"Y\":\n",
    "        np.save('correct_search.npy', worddic) \n",
    "    else:\n",
    "        print(\"sorry it was not helpful, try again\")\n",
    "except:\n",
    "    print(\"no results found\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "af8259ad5c1c9c7a69bd6ea085234cf8fd3a6a37a71ca551828b314c4d89b0ad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
