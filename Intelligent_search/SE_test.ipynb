{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic search with nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import string\n",
    "import random\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "from nltk.corpus import reuters\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package reuters to\n",
      "[nltk_data]     C:\\Users\\flori\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package reuters is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10788"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load 10k reuters news documents \n",
    "nltk.download('reuters')\n",
    "len(reuters.fileids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"ASIAN EXPORTERS FEAR DAMAGE FROM U.S.-JAPAN RIFT\\n  Mounting trade friction between the\\n  U.S. And Japan has raised fears among many of Asia's exporting\\n  nations that the row could inflict far-reaching\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#view text from one document \n",
    "reuters.raw(fileids=['test/14826'])[0:201]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHINA DAILY SAYS VERMIN EAT 712 PCT GRAIN STOCKS\n",
      "  A survey of 19 provinces and seven cities\n",
      "  showed vermin consume between seven and 12 pct of Chinas grain\n",
      "  stocks the China Daily said\n",
      "      It also said that each year 1575 mln tonnes or 25 pct of\n",
      "  Chinas fruit output are left to rot and 21 mln tonnes or up\n",
      "  to 30 pct of its vegetables The paper blamed the waste on\n",
      "  inadequate storage and bad preservation methods\n",
      "      It said the government had launched a national programme to\n",
      "  reduce waste calling for improved technology in storage and\n",
      "  preservation and greater production of additives The paper\n",
      "  gave no further details\n",
      "  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# remove punctuation from all DOCs \n",
    "exclude = set(string.punctuation)\n",
    "alldocslist = []\n",
    "\n",
    "for index, i in  enumerate(reuters.fileids()):\n",
    "    text = reuters.raw(fileids=[i])\n",
    "    text = ''.join(ch for ch in text if ch not in exclude)\n",
    "    alldocslist.append(text)\n",
    "    \n",
    "print(alldocslist[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CHINA', 'DAILY', 'SAYS', 'VERMIN', 'EAT', '712', 'PCT', 'GRAIN', 'STOCKS', 'A', 'survey', 'of', '19', 'provinces', 'and', 'seven', 'cities', 'showed', 'vermin', 'consume', 'between', 'seven', 'and', '12', 'pct', 'of', 'Chinas', 'grain', 'stocks', 'the', 'China', 'Daily', 'said', 'It', 'also', 'said', 'that', 'each', 'year', '1575', 'mln', 'tonnes', 'or', '25', 'pct', 'of', 'Chinas', 'fruit', 'output', 'are', 'left', 'to', 'rot', 'and', '21', 'mln', 'tonnes', 'or', 'up', 'to', '30', 'pct', 'of', 'its', 'vegetables', 'The', 'paper', 'blamed', 'the', 'waste', 'on', 'inadequate', 'storage', 'and', 'bad', 'preservation', 'methods', 'It', 'said', 'the', 'government', 'had', 'launched', 'a', 'national', 'programme', 'to', 'reduce', 'waste', 'calling', 'for', 'improved', 'technology', 'in', 'storage', 'and', 'preservation', 'and', 'greater', 'production', 'of', 'additives', 'The', 'paper', 'gave', 'no', 'further', 'details']\n"
     ]
    }
   ],
   "source": [
    "#tokenize words in all DOCS \n",
    "plot_data = [[]] * len(alldocslist)\n",
    "\n",
    "for doc in alldocslist:\n",
    "    text = doc\n",
    "    tokentext = word_tokenize(text)\n",
    "    plot_data[index].append(tokentext)\n",
    "    \n",
    "print(plot_data[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CHINA',\n",
       " 'DAILY',\n",
       " 'SAYS',\n",
       " 'VERMIN',\n",
       " 'EAT',\n",
       " '712',\n",
       " 'PCT',\n",
       " 'GRAIN',\n",
       " 'STOCKS',\n",
       " 'A']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Navigation: first index gives all documents, second index gives specific document, third index gives words of that doc\n",
    "plot_data[0][1][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['china',\n",
       " 'daily',\n",
       " 'says',\n",
       " 'vermin',\n",
       " 'eat',\n",
       " '712',\n",
       " 'pct',\n",
       " 'grain',\n",
       " 'stocks',\n",
       " 'a']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make all words lower case for all docs \n",
    "for x in range(len(reuters.fileids())):\n",
    "    lowers = [word.lower() for word in plot_data[0][x]]\n",
    "    plot_data[0][x] = lowers\n",
    "\n",
    "plot_data[0][1][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['china',\n",
       " 'daily',\n",
       " 'says',\n",
       " 'vermin',\n",
       " 'eat',\n",
       " '712',\n",
       " 'pct',\n",
       " 'grain',\n",
       " 'stocks',\n",
       " 'survey']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove stop words from all docs \n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "for x in range(len(reuters.fileids())):\n",
    "    filtered_sentence = [w for w in plot_data[0][x] if not w in stop_words]\n",
    "    plot_data[0][x] = filtered_sentence\n",
    "\n",
    "plot_data[0][1][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ltaha',\n",
       " 'automot',\n",
       " 'technolog',\n",
       " 'corp',\n",
       " 'year',\n",
       " 'net',\n",
       " 'shr',\n",
       " '43',\n",
       " 'ct',\n",
       " 'vs']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stem words EXAMPLE (could try others/lemmers )\n",
    "\n",
    "snowball_stemmer = SnowballStemmer(\"english\")\n",
    "stemmed_sentence = [snowball_stemmer.stem(w) for w in filtered_sentence]\n",
    "stemmed_sentence[0:10]\n",
    "\n",
    "porter_stemmer = PorterStemmer()\n",
    "snowball_stemmer = SnowballStemmer(\"english\")\n",
    "stemmed_sentence = [ porter_stemmer.stem(w) for w in filtered_sentence]\n",
    "stemmed_sentence[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create inverse index which gives document number for each document and where word appears\n",
    "\n",
    "#first we need to create a list of all words \n",
    "l = plot_data[0]\n",
    "flatten = [item for sublist in l for item in sublist]\n",
    "words = flatten\n",
    "wordsunique = set(words)\n",
    "wordsunique = list(wordsunique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create functions for TD-IDF / BM25\n",
    "import math\n",
    "from textblob import TextBlob as tb\n",
    "\n",
    "def tf(word, doc):\n",
    "    return doc.count(word) / len(doc)\n",
    "\n",
    "def n_containing(word, doclist):\n",
    "    return sum(1 for doc in doclist if word in doc)\n",
    "\n",
    "def idf(word, doclist):\n",
    "    return math.log(len(doclist) / (0.01 + n_containing(word, doclist)))\n",
    "\n",
    "def tfidf(word, doc, doclist):\n",
    "    return (tf(word, doc) * idf(word, doclist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictonary of words\n",
    "# THIS ONE-TIME INDEXING IS THE MOST PROCESSOR-INTENSIVE STEP AND WILL TAKE TIME TO RUN (BUT ONLY NEEDS TO BE RUN ONCE)\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "plottest = plot_data[0][0:1000]\n",
    "\n",
    "worddic = {}\n",
    "\n",
    "for doc in plottest:\n",
    "    for word in wordsunique:\n",
    "        if word in doc:\n",
    "            word = str(word)\n",
    "            index = plottest.index(doc)\n",
    "            positions = list(np.where(np.array(plottest[index]) == word)[0])\n",
    "            idfs = tfidf(word,doc,plottest)\n",
    "            try:\n",
    "                worddic[word].append([index,positions,idfs])\n",
    "            except:\n",
    "                worddic[word] = []\n",
    "                worddic[word].append([index,positions,idfs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, [0, 23], 0.1131500878815288],\n",
       " [13, [0], 0.06694713532990454],\n",
       " [14, [160], 0.013213250394060107],\n",
       " [28, [51], 0.05821490028687352],\n",
       " [40, [3, 15, 59, 79], 0.14740653650621185],\n",
       " [236, [86], 0.04414096834938761],\n",
       " [281, [70], 0.0565750439407644],\n",
       " [293, [13, 21], 0.11642980057374704],\n",
       " [302, [33], 0.059952658504392124],\n",
       " [342, [55, 146], 0.05391715597039292],\n",
       " [567, [2], 0.06925565723783228],\n",
       " [569, [1014, 1072, 1221], 0.009248261212112677],\n",
       " [612, [20], 0.01998421950146404],\n",
       " [710, [0, 7, 34], 0.17464470086062053],\n",
       " [720, [0, 16], 0.23628400704672192],\n",
       " [721, [0, 6, 27, 78, 82], 0.2028701070603168],\n",
       " [733, [179], 0.021595850106420823],\n",
       " [736, [0, 5, 21, 83], 0.13732745708698368]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the index creates a dic with each word as a KEY and a list of doc indexs, word positions, and td-idf score as VALUES\n",
    "worddic['china']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickel (save) the dictonary to avoid re-calculating\n",
    "np.save('worddic_1000.npy', worddic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['indonesia', 'crude', 'palm', 'oil']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create word search which takes multiple words and finds documents that contain both along with metrics for ranking:\n",
    "\n",
    "    ## (1) Number of occruances of search words \n",
    "    ## (2) TD-IDF score for search words \n",
    "    ## (3) Percentage of search terms\n",
    "    ## (4) Word ordering score \n",
    "    ## (5) Exact match bonus \n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "def search(searchsentence):\n",
    "    try:\n",
    "        # split sentence into individual words \n",
    "        searchsentence = searchsentence.lower()\n",
    "        try:\n",
    "            words = searchsentence.split(' ')\n",
    "        except:\n",
    "            words = list(words)\n",
    "        enddic = {}\n",
    "        idfdic = {}\n",
    "        closedic = {}\n",
    "        \n",
    "        # remove words if not in worddic \n",
    "        realwords = []\n",
    "        for word in words:\n",
    "            if word in list(worddic.keys()):\n",
    "                realwords.append(word)  \n",
    "        words = realwords\n",
    "        numwords = len(words)\n",
    "        \n",
    "        # make metric of number of occurances of all words in each doc & largest total IDF \n",
    "        for word in words:\n",
    "            for indpos in worddic[word]:\n",
    "                index = indpos[0]\n",
    "                amount = len(indpos[1])\n",
    "                idfscore = indpos[2]\n",
    "                enddic[index] = amount\n",
    "                idfdic[index] = idfscore\n",
    "                fullcount_order = sorted(enddic.items(), key=lambda x:x[1], reverse=True)\n",
    "                fullidf_order = sorted(idfdic.items(), key=lambda x:x[1], reverse=True)\n",
    "\n",
    "                \n",
    "        # make metric of what percentage of words appear in each doc\n",
    "        combo = []\n",
    "        alloptions = {k: worddic.get(k, None) for k in (words)}\n",
    "        for worddex in list(alloptions.values()):\n",
    "            for indexpos in worddex:\n",
    "                for indexz in indexpos:\n",
    "                    combo.append(indexz)\n",
    "        comboindex = combo[::3]\n",
    "        combocount = Counter(comboindex)\n",
    "        for key in combocount:\n",
    "            combocount[key] = combocount[key] / numwords\n",
    "        combocount_order = sorted(combocount.items(), key=lambda x:x[1], reverse=True)\n",
    "        \n",
    "        # make metric for if words appear in same order as in search\n",
    "        if len(words) > 1:\n",
    "            x = []\n",
    "            y = []\n",
    "            for record in [worddic[z] for z in words]:\n",
    "                for index in record:\n",
    "                     x.append(index[0])\n",
    "            for i in x:\n",
    "                if x.count(i) > 1:\n",
    "                    y.append(i)\n",
    "            y = list(set(y))\n",
    "\n",
    "            closedic = {}\n",
    "            for wordbig in [worddic[x] for x in words]:\n",
    "                for record in wordbig:\n",
    "                    if record[0] in y:\n",
    "                        index = record[0]\n",
    "                        positions = record[1]\n",
    "                        try:\n",
    "                            closedic[index].append(positions)\n",
    "                        except:\n",
    "                            closedic[index] = []\n",
    "                            closedic[index].append(positions)\n",
    "\n",
    "            x = 0\n",
    "            fdic = {}\n",
    "            for index in y:\n",
    "                csum = []\n",
    "                for seqlist in closedic[index]:\n",
    "                    while x > 0:\n",
    "                        secondlist = seqlist\n",
    "                        x = 0\n",
    "                        sol = [1 for i in firstlist if i + 1 in secondlist]\n",
    "                        csum.append(sol)\n",
    "                        fsum = [item for sublist in csum for item in sublist]\n",
    "                        fsum = sum(fsum)\n",
    "                        fdic[index] = fsum\n",
    "                        fdic_order = sorted(fdic.items(), key=lambda x:x[1], reverse=True)\n",
    "                    while x == 0:\n",
    "                        firstlist = seqlist\n",
    "                        x = x + 1\n",
    "        else:\n",
    "            fdic_order = 0\n",
    "                    \n",
    "        # also the one above should be given a big boost if ALL found together \n",
    "           \n",
    "        \n",
    "        #could make another metric for if they are not next to each other but still close \n",
    "        \n",
    "        \n",
    "        return(searchsentence,words,fullcount_order,combocount_order,fullidf_order,fdic_order)\n",
    "    \n",
    "    except:\n",
    "        return(\"\")\n",
    "\n",
    "\n",
    "search('indonesia crude palm oil')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['crude', 'palm', 'oil']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0 return will give back the search term, the rest will give back metrics (see above)\n",
    "\n",
    "search('indonesia crude palm oil')[1][1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>search term</th>\n",
       "      <th>actual_words_searched</th>\n",
       "      <th>num_occur</th>\n",
       "      <th>percentage_of_terms</th>\n",
       "      <th>td-idf</th>\n",
       "      <th>word_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>china daily says what</td>\n",
       "      <td>[china, daily, says]</td>\n",
       "      <td>[(183, 5), (40, 4), (569, 3), (710, 3), (342, ...</td>\n",
       "      <td>[(1, 1.0), (13, 0.6666666666666666), (14, 0.66...</td>\n",
       "      <td>[(675, 0.5095658223243495), (135, 0.4367707048...</td>\n",
       "      <td>[(1, 3), (293, 1), (720, 1), (721, 1), (736, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>indonesia crude palm oil</td>\n",
       "      <td>[indonesia, crude, palm, oil]</td>\n",
       "      <td>[(33, 13), (621, 12), (34, 11), (209, 8), (123...</td>\n",
       "      <td>[(4, 1.0), (6, 1.0), (209, 0.5), (281, 0.5), (...</td>\n",
       "      <td>[(762, 0.48707909813666866), (266, 0.434203698...</td>\n",
       "      <td>[(34, 6), (4, 5), (660, 5), (6, 4), (268, 2), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>price of nickel</td>\n",
       "      <td>[price, nickel]</td>\n",
       "      <td>[(572, 19), (639, 8), (108, 7), (148, 7), (736...</td>\n",
       "      <td>[(724, 1.0), (4, 0.5), (7, 0.5), (20, 0.5), (2...</td>\n",
       "      <td>[(50, 0.24460301234499893), (537, 0.2066299280...</td>\n",
       "      <td>[(724, 0)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>north yemen sugar</td>\n",
       "      <td>[north, yemen, sugar]</td>\n",
       "      <td>[(700, 12), (96, 8), (494, 7), (296, 6), (525,...</td>\n",
       "      <td>[(30, 1.0), (758, 1.0), (47, 0.666666666666666...</td>\n",
       "      <td>[(494, 0.3808351739278394), (30, 0.35115970582...</td>\n",
       "      <td>[(758, 2), (30, 2), (851, 0), (47, 0)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nippon steel</td>\n",
       "      <td>[nippon, steel]</td>\n",
       "      <td>[(40, 9), (253, 8), (444, 7), (223, 2), (435, ...</td>\n",
       "      <td>[(40, 1.0), (123, 0.5), (223, 0.5), (253, 0.5)...</td>\n",
       "      <td>[(223, 0.5682589478261134), (40, 0.42228417223...</td>\n",
       "      <td>[(40, 5)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>china</td>\n",
       "      <td>[china]</td>\n",
       "      <td>[(721, 5), (40, 4), (736, 4), (569, 3), (710, ...</td>\n",
       "      <td>[(1, 1.0), (13, 1.0), (14, 1.0), (28, 1.0), (4...</td>\n",
       "      <td>[(720, 0.23628400704672192), (721, 0.202870107...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gold</td>\n",
       "      <td>[gold]</td>\n",
       "      <td>[(997, 6), (20, 5), (797, 5), (341, 4), (347, ...</td>\n",
       "      <td>[(8, 1.0), (12, 1.0), (20, 1.0), (32, 1.0), (2...</td>\n",
       "      <td>[(304, 0.30902054113001826), (20, 0.2575171176...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>trade</td>\n",
       "      <td>[trade]</td>\n",
       "      <td>[(0, 15), (169, 10), (544, 10), (761, 8), (273...</td>\n",
       "      <td>[(285, 2.0), (701, 2.0), (713, 2.0), (923, 2.0...</td>\n",
       "      <td>[(223, 0.24728127372797265), (449, 0.247281273...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                search term          actual_words_searched  \\\n",
       "0     china daily says what           [china, daily, says]   \n",
       "1  indonesia crude palm oil  [indonesia, crude, palm, oil]   \n",
       "2           price of nickel                [price, nickel]   \n",
       "3         north yemen sugar          [north, yemen, sugar]   \n",
       "4              nippon steel                [nippon, steel]   \n",
       "5                     china                        [china]   \n",
       "6                      gold                         [gold]   \n",
       "7                     trade                        [trade]   \n",
       "\n",
       "                                           num_occur  \\\n",
       "0  [(183, 5), (40, 4), (569, 3), (710, 3), (342, ...   \n",
       "1  [(33, 13), (621, 12), (34, 11), (209, 8), (123...   \n",
       "2  [(572, 19), (639, 8), (108, 7), (148, 7), (736...   \n",
       "3  [(700, 12), (96, 8), (494, 7), (296, 6), (525,...   \n",
       "4  [(40, 9), (253, 8), (444, 7), (223, 2), (435, ...   \n",
       "5  [(721, 5), (40, 4), (736, 4), (569, 3), (710, ...   \n",
       "6  [(997, 6), (20, 5), (797, 5), (341, 4), (347, ...   \n",
       "7  [(0, 15), (169, 10), (544, 10), (761, 8), (273...   \n",
       "\n",
       "                                 percentage_of_terms  \\\n",
       "0  [(1, 1.0), (13, 0.6666666666666666), (14, 0.66...   \n",
       "1  [(4, 1.0), (6, 1.0), (209, 0.5), (281, 0.5), (...   \n",
       "2  [(724, 1.0), (4, 0.5), (7, 0.5), (20, 0.5), (2...   \n",
       "3  [(30, 1.0), (758, 1.0), (47, 0.666666666666666...   \n",
       "4  [(40, 1.0), (123, 0.5), (223, 0.5), (253, 0.5)...   \n",
       "5  [(1, 1.0), (13, 1.0), (14, 1.0), (28, 1.0), (4...   \n",
       "6  [(8, 1.0), (12, 1.0), (20, 1.0), (32, 1.0), (2...   \n",
       "7  [(285, 2.0), (701, 2.0), (713, 2.0), (923, 2.0...   \n",
       "\n",
       "                                              td-idf  \\\n",
       "0  [(675, 0.5095658223243495), (135, 0.4367707048...   \n",
       "1  [(762, 0.48707909813666866), (266, 0.434203698...   \n",
       "2  [(50, 0.24460301234499893), (537, 0.2066299280...   \n",
       "3  [(494, 0.3808351739278394), (30, 0.35115970582...   \n",
       "4  [(223, 0.5682589478261134), (40, 0.42228417223...   \n",
       "5  [(720, 0.23628400704672192), (721, 0.202870107...   \n",
       "6  [(304, 0.30902054113001826), (20, 0.2575171176...   \n",
       "7  [(223, 0.24728127372797265), (449, 0.247281273...   \n",
       "\n",
       "                                          word_order  \n",
       "0  [(1, 3), (293, 1), (720, 1), (721, 1), (736, 0...  \n",
       "1  [(34, 6), (4, 5), (660, 5), (6, 4), (268, 2), ...  \n",
       "2                                         [(724, 0)]  \n",
       "3             [(758, 2), (30, 2), (851, 0), (47, 0)]  \n",
       "4                                          [(40, 5)]  \n",
       "5                                                  0  \n",
       "6                                                  0  \n",
       "7                                                  0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save metrics to dataframe for use in ranking and machine learning \n",
    "result1 = search('china daily says what')\n",
    "result2 = search('indonesia crude palm oil')\n",
    "result3 = search('price of nickel')\n",
    "result4 = search('north yemen sugar')\n",
    "result5 = search('nippon steel')\n",
    "result6 = search('China')\n",
    "result7 = search('Gold')\n",
    "result8 = search('trade')\n",
    "df = pd.DataFrame([result1,result2,result3,result4,result5,result6,result7,result8])\n",
    "df.columns = ['search term', 'actual_words_searched','num_occur','percentage_of_terms','td-idf','word_order']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CHINA DAILY SAYS VERMIN EAT 712 PCT GRAIN STOCKS\\n  A survey of 19 provinces and seven cities\\n  showed vermin consume between seven and 12 pct of Chinas grain\\n  stocks the China Daily said\\n      It also said that each year 1575 mln tonnes or 25 pct of\\n  Chinas fruit output are left to rot and 21 mln tonnes or up\\n  to 30 pct of its vegetables The paper blamed the waste on\\n  inadequate storage and bad preservation methods\\n      It said the government had launched a national programme to\\n  reduce waste calling for improved technology in storage and\\n  preservation and greater production of additives The paper\\n  gave no further details\\n  \\n\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look to see if the top documents seem to make sense\n",
    "\n",
    "alldocslist[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a simple (non-machine learning) rank and return function\n",
    "\n",
    "def rank(term):\n",
    "    results = search(term)\n",
    "\n",
    "    # get metrics \n",
    "    num_score = results[2]\n",
    "    per_score = results[3]\n",
    "    tfscore = results[4]\n",
    "    order_score = results[5]\n",
    "    \n",
    "    final_candidates = []\n",
    "\n",
    "    # rule1: if high word order score & 100% percentage terms then put at top position\n",
    "    try:\n",
    "        first_candidates = []\n",
    "\n",
    "        for candidates in order_score:\n",
    "            if candidates[1] > 1:\n",
    "                first_candidates.append(candidates[0])\n",
    "\n",
    "        second_candidates = []\n",
    "\n",
    "        for match_candidates in per_score:\n",
    "            if match_candidates[1] == 1:\n",
    "                second_candidates.append(match_candidates[0])\n",
    "            if match_candidates[1] == 1 and match_candidates[0] in first_candidates:\n",
    "                final_candidates.append(match_candidates[0])\n",
    "\n",
    "    # rule2: next add other word order score which are greater than 1 \n",
    "\n",
    "        t3_order = first_candidates[0:3]\n",
    "        for each in t3_order:\n",
    "            if each not in final_candidates:\n",
    "                final_candidates.insert(len(final_candidates),each)\n",
    "\n",
    "    # rule3: next add top td-idf results\n",
    "        final_candidates.insert(len(final_candidates),tfscore[0][0])\n",
    "        final_candidates.insert(len(final_candidates),tfscore[1][0])\n",
    "\n",
    "    # rule4: next add other high percentage score \n",
    "        t3_per = second_candidates[0:3]\n",
    "        for each in t3_per:\n",
    "            if each not in final_candidates:\n",
    "                final_candidates.insert(len(final_candidates),each)\n",
    "\n",
    "    #rule5: next add any other top results for metrics\n",
    "        othertops = [num_score[0][0],per_score[0][0],tfscore[0][0],order_score[0][0]]\n",
    "        for top in othertops:\n",
    "            if top not in final_candidates:\n",
    "                final_candidates.insert(len(final_candidates),top)\n",
    "                \n",
    "    # unless single term searched, in which case just return \n",
    "    except:\n",
    "        othertops = [num_score[0][0],num_score[1][0],num_score[2][0],per_score[0][0],tfscore[0][0]]\n",
    "        for top in othertops:\n",
    "            if top not in final_candidates:\n",
    "                final_candidates.insert(len(final_candidates),top)\n",
    "\n",
    "    for index, results in enumerate(final_candidates):\n",
    "        if index < 5:\n",
    "            print(\"RESULT\", index + 1, \":\", alldocslist[results][0:100],\"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULT 1 : INDONESIA SEES CPO PRICE RISING SHARPLY\n",
      "  Indonesia expects crude palm oil CPO\n",
      "  prices to rise shar ...\n",
      "RESULT 2 : INDONESIAN COMMODITY EXCHANGE MAY EXPAND\n",
      "  The Indonesian Commodity Exchange is\n",
      "  likely to start tr ...\n",
      "RESULT 3 : MALAYSIA MAY NOT MEET 1987 OIL PALM TARGET\n",
      "  Malaysia is unlikely to meet its\n",
      "  targeted output of f ...\n",
      "RESULT 4 : SAUDI ARABIA SEEKING RBD PALM OLEIN\n",
      "  Saudi Arabia is in the market for 4000\n",
      "  tonnes of refined ble ...\n",
      "RESULT 5 : SAUDI ARABIA BUYS RBD PALM OLEIN\n",
      "  Saudi Arabia bought 4000 tonnes of\n",
      "  Malaysian refined bleached d ...\n"
     ]
    }
   ],
   "source": [
    "# example of output \n",
    "rank('indonesia palm oil')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULT 1 : CHINA CHILE TO BUILD COPPER TUBE PLANT IN CHINA\n",
      "  Chinas stateowned Beijing NonFerrous\n",
      "  Metals Indu ...\n",
      "RESULT 2 : NIPPON STEEL DENIES CHINA SEEKING JAPANESE PLANTS\n",
      "  Nippon Steel Corp ltNSTCT denied local\n",
      "  newspap ...\n",
      "RESULT 3 : CHINA RAISES GRAIN PURCHASE PRICES\n",
      "  China has raised the state purchase\n",
      "  prices of corn rice cotto ...\n",
      "RESULT 4 : CHINA DAILY SAYS VERMIN EAT 712 PCT GRAIN STOCKS\n",
      "  A survey of 19 provinces and seven cities\n",
      "  showe ...\n",
      "RESULT 5 : CHINA SULPHURIRON MINE STARTS PRODUCTION\n",
      "  Chinas largest sulphuriron mine has\n",
      "  started trial produ ...\n"
     ]
    }
   ],
   "source": [
    "# example of output \n",
    "rank('china')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pseudo-truth set using first 5 words \n",
    "# Because I don't have a turth set I will generate a pseudo one by pulling terms from the documents - this is far from perfect\n",
    "     # as it may not approximate well peoples actual queries but it will serve well to build the ML architecture \n",
    "\n",
    "df_truth = pd.DataFrame()\n",
    "\n",
    "for doc in plottest:\n",
    "    first_five = doc[0:5]\n",
    "    test_sentence = ' '.join(first_five)\n",
    "    result = search(test_sentence)\n",
    "    df_temp = pd.DataFrame([result])\n",
    "    df_truth= pd.concat([df_truth, df_temp])\n",
    "\n",
    "df_truth['truth'] = range(0,len(plottest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create another psuedo-truth set using random 3 word sequence from docs\n",
    "\n",
    "df_truth1 = pd.DataFrame()\n",
    "seqlen = 3\n",
    "\n",
    "for doc in plottest:\n",
    "    try:\n",
    "        start = random.randint(0,(len(doc)-seqlen))\n",
    "        random_seq = doc[start:start+seqlen]\n",
    "        test_sentence = ' '.join(random_seq)\n",
    "    except:\n",
    "        test_sentence = doc[0]\n",
    "    result = search(test_sentence)\n",
    "    df_temp = pd.DataFrame([result])\n",
    "    df_truth1= pd.concat([df_truth1, df_temp])\n",
    "\n",
    "df_truth1['truth'] = range(0,len(plottest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create another psuedo-truth set using different random 4 word sequence from docs\n",
    "\n",
    "df_truth2 = pd.DataFrame()\n",
    "seqlen = 4\n",
    "\n",
    "for doc in plottest:\n",
    "    try:\n",
    "        start = random.randint(0,(len(doc)-seqlen))\n",
    "        random_seq = doc[start:start+seqlen]\n",
    "        test_sentence = ' '.join(random_seq)\n",
    "    except:\n",
    "        test_sentence = doc[0]\n",
    "    result = search(test_sentence)\n",
    "    df_temp = pd.DataFrame([result])\n",
    "    df_truth2= pd.concat([df_truth2, df_temp])\n",
    "\n",
    "df_truth2['truth'] = range(0,len(plottest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create another psuedo-truth set using different random 2 word sequence from docs\n",
    "\n",
    "df_truth3 = pd.DataFrame()\n",
    "seqlen = 2\n",
    "\n",
    "for doc in plottest:\n",
    "    try:\n",
    "        start = random.randint(0,(len(doc)-seqlen))\n",
    "        random_seq = doc[start:start+seqlen]\n",
    "        test_sentence = ' '.join(random_seq)\n",
    "    except:\n",
    "        test_sentence = doc[0]\n",
    "    result = search(test_sentence)\n",
    "    df_temp = pd.DataFrame([result])\n",
    "    df_truth3= pd.concat([df_truth3, df_temp])\n",
    "\n",
    "df_truth3['truth'] = range(0,len(plottest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the truth sets and save to disk \n",
    "truth_set = pd.concat([df_truth,df_truth1,df_truth2,df_truth3])\n",
    "truth_set.columns = ['search term', 'actual_words_searched','num_occur','percentage_of_terms','td-idf','word_order','truth']\n",
    "truth_set.to_csv(\"truth_set_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>search term</th>\n",
       "      <th>actual_words_searched</th>\n",
       "      <th>num_occur</th>\n",
       "      <th>percentage_of_terms</th>\n",
       "      <th>td-idf</th>\n",
       "      <th>word_order</th>\n",
       "      <th>truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>asian exporters fear damage usjapan</td>\n",
       "      <td>[asian, exporters, fear, damage, usjapan]</td>\n",
       "      <td>[(569, 4), (453, 3), (138, 2), (276, 2), (582,...</td>\n",
       "      <td>[(0, 1.0), (761, 0.4), (111, 0.4), (138, 0.2),...</td>\n",
       "      <td>[(586, 0.3862756764125228), (594, 0.3862756764...</td>\n",
       "      <td>[(0, 4), (761, 0), (111, 0)]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>china daily says vermin eat</td>\n",
       "      <td>[china, daily, says, vermin, eat]</td>\n",
       "      <td>[(183, 5), (40, 4), (569, 3), (710, 3), (342, ...</td>\n",
       "      <td>[(1, 1.0), (13, 0.4), (14, 0.4), (281, 0.4), (...</td>\n",
       "      <td>[(675, 0.5095658223243495), (135, 0.4367707048...</td>\n",
       "      <td>[(1, 5), (293, 1), (720, 1), (721, 1), (736, 0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>japan revise longterm energy demand</td>\n",
       "      <td>[japan, revise, longterm, energy, demand]</td>\n",
       "      <td>[(728, 10), (0, 9), (282, 8), (691, 8), (272, ...</td>\n",
       "      <td>[(2, 1.0), (14, 0.4), (279, 0.4), (285, 0.4), ...</td>\n",
       "      <td>[(684, 0.29388161853201494), (919, 0.286868066...</td>\n",
       "      <td>[(2, 7), (701, 0), (663, 0), (681, 0), (695, 0...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thai trade deficit widens first</td>\n",
       "      <td>[thai, trade, deficit, widens, first]</td>\n",
       "      <td>[(273, 21), (544, 10), (761, 8), (858, 7), (22...</td>\n",
       "      <td>[(701, 1.2), (3, 1.0), (923, 0.8), (18, 0.6), ...</td>\n",
       "      <td>[(552, 0.36954211323937414), (223, 0.247281273...</td>\n",
       "      <td>[(273, 6), (3, 5), (384, 2), (385, 2), (291, 2...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>indonesia sees cpo price rising</td>\n",
       "      <td>[indonesia, sees, cpo, price, rising]</td>\n",
       "      <td>[(572, 19), (639, 8), (108, 7), (148, 7), (736...</td>\n",
       "      <td>[(4, 1.0), (294, 0.6), (6, 0.4), (311, 0.4), (...</td>\n",
       "      <td>[(212, 0.40873824949762244), (366, 0.408738249...</td>\n",
       "      <td>[(4, 4), (6, 0), (279, 0), (792, 0), (285, 0),...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>australian foreign ship ban ends</td>\n",
       "      <td>[australian, foreign, ship, ban, ends]</td>\n",
       "      <td>[(510, 8), (408, 6), (18, 5), (23, 5), (621, 5...</td>\n",
       "      <td>[(5, 1.0), (61, 1.0), (0, 0.4), (31, 0.4), (32...</td>\n",
       "      <td>[(510, 0.27446283551031375), (229, 0.131136680...</td>\n",
       "      <td>[(5, 4), (61, 4), (0, 0), (32, 0), (36, 0), (7...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>indonesian commodity exchange may expand</td>\n",
       "      <td>[indonesian, commodity, exchange, may, expand]</td>\n",
       "      <td>[(183, 11), (596, 5), (271, 3), (290, 3), (382...</td>\n",
       "      <td>[(6, 1.0), (735, 0.6), (9, 0.6), (123, 0.4), (...</td>\n",
       "      <td>[(659, 0.24078345037131432), (507, 0.197605473...</td>\n",
       "      <td>[(6, 6), (663, 1), (0, 0), (384, 0), (387, 0),...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sri lanka gets usda approval</td>\n",
       "      <td>[sri, lanka, gets, usda, approval]</td>\n",
       "      <td>[(584, 7), (814, 5), (569, 4), (208, 3), (561,...</td>\n",
       "      <td>[(7, 1.0), (640, 0.6), (377, 0.4), (701, 0.4),...</td>\n",
       "      <td>[(549, 0.26365820837225185), (550, 0.241686691...</td>\n",
       "      <td>[(7, 4), (377, 2), (640, 1), (724, 0), (701, 0)]</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>western mining open new gold</td>\n",
       "      <td>[western, mining, open, new, gold]</td>\n",
       "      <td>[(997, 6), (20, 5), (569, 5), (384, 5), (797, ...</td>\n",
       "      <td>[(8, 1.0), (701, 0.8), (724, 0.8), (20, 0.6), ...</td>\n",
       "      <td>[(972, 0.38161201272063366), (983, 0.319308010...</td>\n",
       "      <td>[(8, 5), (716, 2), (257, 1), (12, 1), (276, 1)...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sumitomo bank aims quick recovery</td>\n",
       "      <td>[sumitomo, bank, aims, quick, recovery]</td>\n",
       "      <td>[(118, 6), (336, 6), (374, 6), (691, 6), (798,...</td>\n",
       "      <td>[(9, 1.0), (32, 0.4), (33, 0.4), (285, 0.4), (...</td>\n",
       "      <td>[(684, 0.22331565055000002), (709, 0.200984085...</td>\n",
       "      <td>[(9, 6), (32, 0), (33, 0), (322, 0), (384, 0),...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                search term  \\\n",
       "0       asian exporters fear damage usjapan   \n",
       "0               china daily says vermin eat   \n",
       "0       japan revise longterm energy demand   \n",
       "0           thai trade deficit widens first   \n",
       "0           indonesia sees cpo price rising   \n",
       "0          australian foreign ship ban ends   \n",
       "0  indonesian commodity exchange may expand   \n",
       "0              sri lanka gets usda approval   \n",
       "0              western mining open new gold   \n",
       "0         sumitomo bank aims quick recovery   \n",
       "\n",
       "                            actual_words_searched  \\\n",
       "0       [asian, exporters, fear, damage, usjapan]   \n",
       "0               [china, daily, says, vermin, eat]   \n",
       "0       [japan, revise, longterm, energy, demand]   \n",
       "0           [thai, trade, deficit, widens, first]   \n",
       "0           [indonesia, sees, cpo, price, rising]   \n",
       "0          [australian, foreign, ship, ban, ends]   \n",
       "0  [indonesian, commodity, exchange, may, expand]   \n",
       "0              [sri, lanka, gets, usda, approval]   \n",
       "0              [western, mining, open, new, gold]   \n",
       "0         [sumitomo, bank, aims, quick, recovery]   \n",
       "\n",
       "                                           num_occur  \\\n",
       "0  [(569, 4), (453, 3), (138, 2), (276, 2), (582,...   \n",
       "0  [(183, 5), (40, 4), (569, 3), (710, 3), (342, ...   \n",
       "0  [(728, 10), (0, 9), (282, 8), (691, 8), (272, ...   \n",
       "0  [(273, 21), (544, 10), (761, 8), (858, 7), (22...   \n",
       "0  [(572, 19), (639, 8), (108, 7), (148, 7), (736...   \n",
       "0  [(510, 8), (408, 6), (18, 5), (23, 5), (621, 5...   \n",
       "0  [(183, 11), (596, 5), (271, 3), (290, 3), (382...   \n",
       "0  [(584, 7), (814, 5), (569, 4), (208, 3), (561,...   \n",
       "0  [(997, 6), (20, 5), (569, 5), (384, 5), (797, ...   \n",
       "0  [(118, 6), (336, 6), (374, 6), (691, 6), (798,...   \n",
       "\n",
       "                                 percentage_of_terms  \\\n",
       "0  [(0, 1.0), (761, 0.4), (111, 0.4), (138, 0.2),...   \n",
       "0  [(1, 1.0), (13, 0.4), (14, 0.4), (281, 0.4), (...   \n",
       "0  [(2, 1.0), (14, 0.4), (279, 0.4), (285, 0.4), ...   \n",
       "0  [(701, 1.2), (3, 1.0), (923, 0.8), (18, 0.6), ...   \n",
       "0  [(4, 1.0), (294, 0.6), (6, 0.4), (311, 0.4), (...   \n",
       "0  [(5, 1.0), (61, 1.0), (0, 0.4), (31, 0.4), (32...   \n",
       "0  [(6, 1.0), (735, 0.6), (9, 0.6), (123, 0.4), (...   \n",
       "0  [(7, 1.0), (640, 0.6), (377, 0.4), (701, 0.4),...   \n",
       "0  [(8, 1.0), (701, 0.8), (724, 0.8), (20, 0.6), ...   \n",
       "0  [(9, 1.0), (32, 0.4), (33, 0.4), (285, 0.4), (...   \n",
       "\n",
       "                                              td-idf  \\\n",
       "0  [(586, 0.3862756764125228), (594, 0.3862756764...   \n",
       "0  [(675, 0.5095658223243495), (135, 0.4367707048...   \n",
       "0  [(684, 0.29388161853201494), (919, 0.286868066...   \n",
       "0  [(552, 0.36954211323937414), (223, 0.247281273...   \n",
       "0  [(212, 0.40873824949762244), (366, 0.408738249...   \n",
       "0  [(510, 0.27446283551031375), (229, 0.131136680...   \n",
       "0  [(659, 0.24078345037131432), (507, 0.197605473...   \n",
       "0  [(549, 0.26365820837225185), (550, 0.241686691...   \n",
       "0  [(972, 0.38161201272063366), (983, 0.319308010...   \n",
       "0  [(684, 0.22331565055000002), (709, 0.200984085...   \n",
       "\n",
       "                                          word_order  truth  \n",
       "0                       [(0, 4), (761, 0), (111, 0)]      0  \n",
       "0  [(1, 5), (293, 1), (720, 1), (721, 1), (736, 0...      1  \n",
       "0  [(2, 7), (701, 0), (663, 0), (681, 0), (695, 0...      2  \n",
       "0  [(273, 6), (3, 5), (384, 2), (385, 2), (291, 2...      3  \n",
       "0  [(4, 4), (6, 0), (279, 0), (792, 0), (285, 0),...      4  \n",
       "0  [(5, 4), (61, 4), (0, 0), (32, 0), (36, 0), (7...      5  \n",
       "0  [(6, 6), (663, 1), (0, 0), (384, 0), (387, 0),...      6  \n",
       "0   [(7, 4), (377, 2), (640, 1), (724, 0), (701, 0)]      7  \n",
       "0  [(8, 5), (716, 2), (257, 1), (12, 1), (276, 1)...      8  \n",
       "0  [(9, 6), (32, 0), (33, 0), (322, 0), (384, 0),...      9  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truth_set[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>search term</th>\n",
       "      <th>actual_words_searched</th>\n",
       "      <th>num_occur</th>\n",
       "      <th>percentage_of_terms</th>\n",
       "      <th>td-idf</th>\n",
       "      <th>word_order</th>\n",
       "      <th>truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>asian exporters fear damage usjapan</td>\n",
       "      <td>[asian, exporters, fear, damage, usjapan]</td>\n",
       "      <td>[(569, 4), (453, 3), (138, 2), (276, 2), (582,...</td>\n",
       "      <td>[(0, 1.0), (761, 0.4), (111, 0.4), (138, 0.2),...</td>\n",
       "      <td>[(586, 0.3862756764125228), (594, 0.3862756764...</td>\n",
       "      <td>[(0, 4), (761, 0), (111, 0)]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>china daily says vermin eat</td>\n",
       "      <td>[china, daily, says, vermin, eat]</td>\n",
       "      <td>[(183, 5), (40, 4), (569, 3), (710, 3), (342, ...</td>\n",
       "      <td>[(1, 1.0), (13, 0.4), (14, 0.4), (281, 0.4), (...</td>\n",
       "      <td>[(675, 0.5095658223243495), (135, 0.4367707048...</td>\n",
       "      <td>[(1, 5), (293, 1), (720, 1), (721, 1), (736, 0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>japan revise longterm energy demand</td>\n",
       "      <td>[japan, revise, longterm, energy, demand]</td>\n",
       "      <td>[(728, 10), (0, 9), (282, 8), (691, 8), (272, ...</td>\n",
       "      <td>[(2, 1.0), (14, 0.4), (279, 0.4), (285, 0.4), ...</td>\n",
       "      <td>[(684, 0.29388161853201494), (919, 0.286868066...</td>\n",
       "      <td>[(2, 7), (701, 0), (663, 0), (681, 0), (695, 0...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           search term  \\\n",
       "0  asian exporters fear damage usjapan   \n",
       "0          china daily says vermin eat   \n",
       "0  japan revise longterm energy demand   \n",
       "\n",
       "                       actual_words_searched  \\\n",
       "0  [asian, exporters, fear, damage, usjapan]   \n",
       "0          [china, daily, says, vermin, eat]   \n",
       "0  [japan, revise, longterm, energy, demand]   \n",
       "\n",
       "                                           num_occur  \\\n",
       "0  [(569, 4), (453, 3), (138, 2), (276, 2), (582,...   \n",
       "0  [(183, 5), (40, 4), (569, 3), (710, 3), (342, ...   \n",
       "0  [(728, 10), (0, 9), (282, 8), (691, 8), (272, ...   \n",
       "\n",
       "                                 percentage_of_terms  \\\n",
       "0  [(0, 1.0), (761, 0.4), (111, 0.4), (138, 0.2),...   \n",
       "0  [(1, 1.0), (13, 0.4), (14, 0.4), (281, 0.4), (...   \n",
       "0  [(2, 1.0), (14, 0.4), (279, 0.4), (285, 0.4), ...   \n",
       "\n",
       "                                              td-idf  \\\n",
       "0  [(586, 0.3862756764125228), (594, 0.3862756764...   \n",
       "0  [(675, 0.5095658223243495), (135, 0.4367707048...   \n",
       "0  [(684, 0.29388161853201494), (919, 0.286868066...   \n",
       "\n",
       "                                          word_order  truth  \n",
       "0                       [(0, 4), (761, 0), (111, 0)]      0  \n",
       "0  [(1, 5), (293, 1), (720, 1), (721, 1), (736, 0...      1  \n",
       "0  [(2, 7), (701, 0), (663, 0), (681, 0), (695, 0...      2  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truth_set\n",
    "test_set = truth_set[0:3]\n",
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>search term</th>\n",
       "      <th>actual_words_searched</th>\n",
       "      <th>num_occur</th>\n",
       "      <th>percentage_of_terms</th>\n",
       "      <th>td-idf</th>\n",
       "      <th>word_order</th>\n",
       "      <th>(num_occur, index, 0)</th>\n",
       "      <th>(num_occur, score, 0)</th>\n",
       "      <th>(num_occur, index, 1)</th>\n",
       "      <th>(num_occur, score, 1)</th>\n",
       "      <th>...</th>\n",
       "      <th>(word_order, score, 0)</th>\n",
       "      <th>(word_order, index, 1)</th>\n",
       "      <th>(word_order, score, 1)</th>\n",
       "      <th>(word_order, index, 2)</th>\n",
       "      <th>(word_order, score, 2)</th>\n",
       "      <th>truth</th>\n",
       "      <th>(word_order, index, 3)</th>\n",
       "      <th>(word_order, score, 3)</th>\n",
       "      <th>(word_order, index, 4)</th>\n",
       "      <th>(word_order, score, 4)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>china daily says vermin eat</td>\n",
       "      <td>[china, daily, says, vermin, eat]</td>\n",
       "      <td>[(183, 5), (40, 4), (569, 3), (710, 3), (342, ...</td>\n",
       "      <td>[(1, 1.0), (13, 0.4), (14, 0.4), (281, 0.4), (...</td>\n",
       "      <td>[(675, 0.5095658223243495), (135, 0.4367707048...</td>\n",
       "      <td>[(1, 5), (293, 1), (720, 1), (721, 1), (736, 0...</td>\n",
       "      <td>183</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>293.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>720.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>721.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>736.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>japan revise longterm energy demand</td>\n",
       "      <td>[japan, revise, longterm, energy, demand]</td>\n",
       "      <td>[(728, 10), (0, 9), (282, 8), (691, 8), (272, ...</td>\n",
       "      <td>[(2, 1.0), (14, 0.4), (279, 0.4), (285, 0.4), ...</td>\n",
       "      <td>[(684, 0.29388161853201494), (919, 0.286868066...</td>\n",
       "      <td>[(2, 7), (701, 0), (663, 0), (681, 0), (695, 0...</td>\n",
       "      <td>728</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>701.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>663.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>681.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>695.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thai trade deficit widens first</td>\n",
       "      <td>[thai, trade, deficit, widens, first]</td>\n",
       "      <td>[(273, 21), (544, 10), (761, 8), (858, 7), (22...</td>\n",
       "      <td>[(701, 1.2), (3, 1.0), (923, 0.8), (18, 0.6), ...</td>\n",
       "      <td>[(552, 0.36954211323937414), (223, 0.247281273...</td>\n",
       "      <td>[(273, 6), (3, 5), (384, 2), (385, 2), (291, 2...</td>\n",
       "      <td>273</td>\n",
       "      <td>21</td>\n",
       "      <td>544</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>385.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>291.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>indonesia sees cpo price rising</td>\n",
       "      <td>[indonesia, sees, cpo, price, rising]</td>\n",
       "      <td>[(572, 19), (639, 8), (108, 7), (148, 7), (736...</td>\n",
       "      <td>[(4, 1.0), (294, 0.6), (6, 0.4), (311, 0.4), (...</td>\n",
       "      <td>[(212, 0.40873824949762244), (366, 0.408738249...</td>\n",
       "      <td>[(4, 4), (6, 0), (279, 0), (792, 0), (285, 0),...</td>\n",
       "      <td>572</td>\n",
       "      <td>19</td>\n",
       "      <td>639</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>279.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>792.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>australian foreign ship ban ends</td>\n",
       "      <td>[australian, foreign, ship, ban, ends]</td>\n",
       "      <td>[(510, 8), (408, 6), (18, 5), (23, 5), (621, 5...</td>\n",
       "      <td>[(5, 1.0), (61, 1.0), (0, 0.4), (31, 0.4), (32...</td>\n",
       "      <td>[(510, 0.27446283551031375), (229, 0.131136680...</td>\n",
       "      <td>[(5, 4), (61, 4), (0, 0), (32, 0), (36, 0), (7...</td>\n",
       "      <td>510</td>\n",
       "      <td>8</td>\n",
       "      <td>408</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>61.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           search term  \\\n",
       "0          china daily says vermin eat   \n",
       "0  japan revise longterm energy demand   \n",
       "0      thai trade deficit widens first   \n",
       "0      indonesia sees cpo price rising   \n",
       "0     australian foreign ship ban ends   \n",
       "\n",
       "                       actual_words_searched  \\\n",
       "0          [china, daily, says, vermin, eat]   \n",
       "0  [japan, revise, longterm, energy, demand]   \n",
       "0      [thai, trade, deficit, widens, first]   \n",
       "0      [indonesia, sees, cpo, price, rising]   \n",
       "0     [australian, foreign, ship, ban, ends]   \n",
       "\n",
       "                                           num_occur  \\\n",
       "0  [(183, 5), (40, 4), (569, 3), (710, 3), (342, ...   \n",
       "0  [(728, 10), (0, 9), (282, 8), (691, 8), (272, ...   \n",
       "0  [(273, 21), (544, 10), (761, 8), (858, 7), (22...   \n",
       "0  [(572, 19), (639, 8), (108, 7), (148, 7), (736...   \n",
       "0  [(510, 8), (408, 6), (18, 5), (23, 5), (621, 5...   \n",
       "\n",
       "                                 percentage_of_terms  \\\n",
       "0  [(1, 1.0), (13, 0.4), (14, 0.4), (281, 0.4), (...   \n",
       "0  [(2, 1.0), (14, 0.4), (279, 0.4), (285, 0.4), ...   \n",
       "0  [(701, 1.2), (3, 1.0), (923, 0.8), (18, 0.6), ...   \n",
       "0  [(4, 1.0), (294, 0.6), (6, 0.4), (311, 0.4), (...   \n",
       "0  [(5, 1.0), (61, 1.0), (0, 0.4), (31, 0.4), (32...   \n",
       "\n",
       "                                              td-idf  \\\n",
       "0  [(675, 0.5095658223243495), (135, 0.4367707048...   \n",
       "0  [(684, 0.29388161853201494), (919, 0.286868066...   \n",
       "0  [(552, 0.36954211323937414), (223, 0.247281273...   \n",
       "0  [(212, 0.40873824949762244), (366, 0.408738249...   \n",
       "0  [(510, 0.27446283551031375), (229, 0.131136680...   \n",
       "\n",
       "                                          word_order  (num_occur, index, 0)  \\\n",
       "0  [(1, 5), (293, 1), (720, 1), (721, 1), (736, 0...                    183   \n",
       "0  [(2, 7), (701, 0), (663, 0), (681, 0), (695, 0...                    728   \n",
       "0  [(273, 6), (3, 5), (384, 2), (385, 2), (291, 2...                    273   \n",
       "0  [(4, 4), (6, 0), (279, 0), (792, 0), (285, 0),...                    572   \n",
       "0  [(5, 4), (61, 4), (0, 0), (32, 0), (36, 0), (7...                    510   \n",
       "\n",
       "   (num_occur, score, 0)  (num_occur, index, 1)  (num_occur, score, 1)  ...  \\\n",
       "0                      5                     40                      4  ...   \n",
       "0                     10                      0                      9  ...   \n",
       "0                     21                    544                     10  ...   \n",
       "0                     19                    639                      8  ...   \n",
       "0                      8                    408                      6  ...   \n",
       "\n",
       "   (word_order, score, 0)  (word_order, index, 1)  (word_order, score, 1)  \\\n",
       "0                       5                   293.0                     1.0   \n",
       "0                       7                   701.0                     0.0   \n",
       "0                       6                     3.0                     5.0   \n",
       "0                       4                     6.0                     0.0   \n",
       "0                       4                    61.0                     4.0   \n",
       "\n",
       "   (word_order, index, 2)  (word_order, score, 2)  truth  \\\n",
       "0                   720.0                     1.0      1   \n",
       "0                   663.0                     0.0      2   \n",
       "0                   384.0                     2.0      3   \n",
       "0                   279.0                     0.0      4   \n",
       "0                     0.0                     0.0      5   \n",
       "\n",
       "   (word_order, index, 3)  (word_order, score, 3)  (word_order, index, 4)  \\\n",
       "0                   721.0                     1.0                   736.0   \n",
       "0                   681.0                     0.0                   695.0   \n",
       "0                   385.0                     2.0                   291.0   \n",
       "0                   792.0                     0.0                   285.0   \n",
       "0                    32.0                     0.0                    36.0   \n",
       "\n",
       "   (word_order, score, 4)  \n",
       "0                     0.0  \n",
       "0                     0.0  \n",
       "0                     2.0  \n",
       "0                     0.0  \n",
       "0                     0.0  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert to long format for ML \n",
    "# WARNING AGAIN THIS IS A SLOW PROCESS DUE TO RAM ILOC - COULD BE OPTIMISED FOR FASTER PERFORMANCE \n",
    "# BUG When min(maxnum, len(truth_set) <- is a int not a list because of very short variable length)\n",
    "\n",
    "# row is row\n",
    "# column is variable\n",
    "# i is the result \n",
    "\n",
    "final_set =  pd.DataFrame()\n",
    "test_set = truth_set[1:100]\n",
    "maxnum = 5\n",
    "\n",
    "for row in range(0,len(test_set.index)):\n",
    "    test_set = truth_set[1:100]\n",
    "    for col in range(2,6):\n",
    "        for i in range(0,min(maxnum,len(truth_set.iloc[row][col]))):\n",
    "            x = pd.DataFrame([truth_set.iloc[row][col][i]])\n",
    "            x['truth'] = truth_set.iloc[row]['truth']\n",
    "            x.columns = [(str(truth_set.columns[col]),\"index\",i),(str(truth_set.columns[col]),\"score\",i),'truth']\n",
    "            test_set = test_set.merge(x,on='truth')\n",
    "    final_set = pd.concat([final_set,test_set])\n",
    "        \n",
    "final_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_set.to_csv(\"ML_set_100.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\flori\\AppData\\Local\\Temp\\ipykernel_8036\\58453081.py:1: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  final_set2 = final_set.drop(['actual_words_searched','num_occur','percentage_of_terms','search term','td-idf','word_order'], 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(num_occur, index, 0)</th>\n",
       "      <th>(num_occur, score, 0)</th>\n",
       "      <th>(num_occur, index, 1)</th>\n",
       "      <th>(num_occur, score, 1)</th>\n",
       "      <th>(num_occur, index, 2)</th>\n",
       "      <th>(num_occur, score, 2)</th>\n",
       "      <th>(num_occur, index, 3)</th>\n",
       "      <th>(num_occur, score, 3)</th>\n",
       "      <th>(num_occur, index, 4)</th>\n",
       "      <th>(num_occur, score, 4)</th>\n",
       "      <th>...</th>\n",
       "      <th>(word_order, score, 0)</th>\n",
       "      <th>(word_order, index, 1)</th>\n",
       "      <th>(word_order, score, 1)</th>\n",
       "      <th>(word_order, index, 2)</th>\n",
       "      <th>(word_order, score, 2)</th>\n",
       "      <th>truth</th>\n",
       "      <th>(word_order, index, 3)</th>\n",
       "      <th>(word_order, score, 3)</th>\n",
       "      <th>(word_order, index, 4)</th>\n",
       "      <th>(word_order, score, 4)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>183</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>569</td>\n",
       "      <td>3</td>\n",
       "      <td>710</td>\n",
       "      <td>3</td>\n",
       "      <td>342</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>293.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>720.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>721.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>736.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>728</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>282</td>\n",
       "      <td>8</td>\n",
       "      <td>691</td>\n",
       "      <td>8</td>\n",
       "      <td>272</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>701.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>663.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>681.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>695.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>273</td>\n",
       "      <td>21</td>\n",
       "      <td>544</td>\n",
       "      <td>10</td>\n",
       "      <td>761</td>\n",
       "      <td>8</td>\n",
       "      <td>858</td>\n",
       "      <td>7</td>\n",
       "      <td>224</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>385.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>291.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>572</td>\n",
       "      <td>19</td>\n",
       "      <td>639</td>\n",
       "      <td>8</td>\n",
       "      <td>108</td>\n",
       "      <td>7</td>\n",
       "      <td>148</td>\n",
       "      <td>7</td>\n",
       "      <td>736</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>279.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>792.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>510</td>\n",
       "      <td>8</td>\n",
       "      <td>408</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>621</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>61.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   (num_occur, index, 0)  (num_occur, score, 0)  (num_occur, index, 1)  \\\n",
       "0                    183                      5                     40   \n",
       "0                    728                     10                      0   \n",
       "0                    273                     21                    544   \n",
       "0                    572                     19                    639   \n",
       "0                    510                      8                    408   \n",
       "\n",
       "   (num_occur, score, 1)  (num_occur, index, 2)  (num_occur, score, 2)  \\\n",
       "0                      4                    569                      3   \n",
       "0                      9                    282                      8   \n",
       "0                     10                    761                      8   \n",
       "0                      8                    108                      7   \n",
       "0                      6                     18                      5   \n",
       "\n",
       "   (num_occur, index, 3)  (num_occur, score, 3)  (num_occur, index, 4)  \\\n",
       "0                    710                      3                    342   \n",
       "0                    691                      8                    272   \n",
       "0                    858                      7                    224   \n",
       "0                    148                      7                    736   \n",
       "0                     23                      5                    621   \n",
       "\n",
       "   (num_occur, score, 4)  ...  (word_order, score, 0)  (word_order, index, 1)  \\\n",
       "0                      2  ...                       5                   293.0   \n",
       "0                      8  ...                       7                   701.0   \n",
       "0                      6  ...                       6                     3.0   \n",
       "0                      6  ...                       4                     6.0   \n",
       "0                      5  ...                       4                    61.0   \n",
       "\n",
       "   (word_order, score, 1)  (word_order, index, 2)  (word_order, score, 2)  \\\n",
       "0                     1.0                   720.0                     1.0   \n",
       "0                     0.0                   663.0                     0.0   \n",
       "0                     5.0                   384.0                     2.0   \n",
       "0                     0.0                   279.0                     0.0   \n",
       "0                     4.0                     0.0                     0.0   \n",
       "\n",
       "   truth  (word_order, index, 3)  (word_order, score, 3)  \\\n",
       "0      1                   721.0                     1.0   \n",
       "0      2                   681.0                     0.0   \n",
       "0      3                   385.0                     2.0   \n",
       "0      4                   792.0                     0.0   \n",
       "0      5                    32.0                     0.0   \n",
       "\n",
       "   (word_order, index, 4)  (word_order, score, 4)  \n",
       "0                   736.0                     0.0  \n",
       "0                   695.0                     0.0  \n",
       "0                   291.0                     2.0  \n",
       "0                   285.0                     0.0  \n",
       "0                    36.0                     0.0  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_set2 = final_set.drop(['actual_words_searched','num_occur','percentage_of_terms','search term','td-idf','word_order'], 1)\n",
    "final_set2.to_csv(\"ML_set_100_3.csv\")\n",
    "final_set2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(num_occur, index, 0)</th>\n",
       "      <th>(num_occur, score, 0)</th>\n",
       "      <th>(num_occur, index, 1)</th>\n",
       "      <th>(num_occur, score, 1)</th>\n",
       "      <th>(num_occur, index, 2)</th>\n",
       "      <th>(num_occur, score, 2)</th>\n",
       "      <th>(num_occur, index, 3)</th>\n",
       "      <th>(num_occur, score, 3)</th>\n",
       "      <th>(num_occur, index, 4)</th>\n",
       "      <th>(num_occur, score, 4)</th>\n",
       "      <th>...</th>\n",
       "      <th>(word_order, score, 0)</th>\n",
       "      <th>(word_order, index, 1)</th>\n",
       "      <th>(word_order, score, 1)</th>\n",
       "      <th>(word_order, index, 2)</th>\n",
       "      <th>(word_order, score, 2)</th>\n",
       "      <th>truth</th>\n",
       "      <th>(word_order, index, 3)</th>\n",
       "      <th>(word_order, score, 3)</th>\n",
       "      <th>(word_order, index, 4)</th>\n",
       "      <th>(word_order, score, 4)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>183</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>569</td>\n",
       "      <td>3</td>\n",
       "      <td>710</td>\n",
       "      <td>3</td>\n",
       "      <td>342</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>293.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>720.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>721.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>736.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>728</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>282</td>\n",
       "      <td>8</td>\n",
       "      <td>691</td>\n",
       "      <td>8</td>\n",
       "      <td>272</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>701.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>663.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>681.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>695.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>273</td>\n",
       "      <td>21</td>\n",
       "      <td>544</td>\n",
       "      <td>10</td>\n",
       "      <td>761</td>\n",
       "      <td>8</td>\n",
       "      <td>858</td>\n",
       "      <td>7</td>\n",
       "      <td>224</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>385.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>291.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>572</td>\n",
       "      <td>19</td>\n",
       "      <td>639</td>\n",
       "      <td>8</td>\n",
       "      <td>108</td>\n",
       "      <td>7</td>\n",
       "      <td>148</td>\n",
       "      <td>7</td>\n",
       "      <td>736</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>279.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>792.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>510</td>\n",
       "      <td>8</td>\n",
       "      <td>408</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>621</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>61.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>183</td>\n",
       "      <td>11</td>\n",
       "      <td>596</td>\n",
       "      <td>5</td>\n",
       "      <td>271</td>\n",
       "      <td>3</td>\n",
       "      <td>290</td>\n",
       "      <td>3</td>\n",
       "      <td>382</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>663.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>384.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>387.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>584</td>\n",
       "      <td>7</td>\n",
       "      <td>814</td>\n",
       "      <td>5</td>\n",
       "      <td>569</td>\n",
       "      <td>4</td>\n",
       "      <td>208</td>\n",
       "      <td>3</td>\n",
       "      <td>561</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>377.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>724.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>701.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>997</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>569</td>\n",
       "      <td>5</td>\n",
       "      <td>384</td>\n",
       "      <td>5</td>\n",
       "      <td>797</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>716.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>257.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>118</td>\n",
       "      <td>6</td>\n",
       "      <td>336</td>\n",
       "      <td>6</td>\n",
       "      <td>374</td>\n",
       "      <td>6</td>\n",
       "      <td>691</td>\n",
       "      <td>6</td>\n",
       "      <td>798</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>322.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>148</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "      <td>532</td>\n",
       "      <td>4</td>\n",
       "      <td>311</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>281.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows  41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   (num_occur, index, 0)  (num_occur, score, 0)  (num_occur, index, 1)  \\\n",
       "0                    183                      5                     40   \n",
       "0                    728                     10                      0   \n",
       "0                    273                     21                    544   \n",
       "0                    572                     19                    639   \n",
       "0                    510                      8                    408   \n",
       "0                    183                     11                    596   \n",
       "0                    584                      7                    814   \n",
       "0                    997                      6                     20   \n",
       "0                    118                      6                    336   \n",
       "0                    148                      5                      4   \n",
       "\n",
       "   (num_occur, score, 1)  (num_occur, index, 2)  (num_occur, score, 2)  \\\n",
       "0                      4                    569                      3   \n",
       "0                      9                    282                      8   \n",
       "0                     10                    761                      8   \n",
       "0                      8                    108                      7   \n",
       "0                      6                     18                      5   \n",
       "0                      5                    271                      3   \n",
       "0                      5                    569                      4   \n",
       "0                      5                    569                      5   \n",
       "0                      6                    374                      6   \n",
       "0                      4                     26                      4   \n",
       "\n",
       "   (num_occur, index, 3)  (num_occur, score, 3)  (num_occur, index, 4)  \\\n",
       "0                    710                      3                    342   \n",
       "0                    691                      8                    272   \n",
       "0                    858                      7                    224   \n",
       "0                    148                      7                    736   \n",
       "0                     23                      5                    621   \n",
       "0                    290                      3                    382   \n",
       "0                    208                      3                    561   \n",
       "0                    384                      5                    797   \n",
       "0                    691                      6                    798   \n",
       "0                    532                      4                    311   \n",
       "\n",
       "   (num_occur, score, 4)  ...  (word_order, score, 0)  (word_order, index, 1)  \\\n",
       "0                      2  ...                       5                   293.0   \n",
       "0                      8  ...                       7                   701.0   \n",
       "0                      6  ...                       6                     3.0   \n",
       "0                      6  ...                       4                     6.0   \n",
       "0                      5  ...                       4                    61.0   \n",
       "0                      3  ...                       6                   663.0   \n",
       "0                      3  ...                       4                   377.0   \n",
       "0                      5  ...                       5                   716.0   \n",
       "0                      6  ...                       6                    32.0   \n",
       "0                      3  ...                       4                   281.0   \n",
       "\n",
       "   (word_order, score, 1)  (word_order, index, 2)  (word_order, score, 2)  \\\n",
       "0                     1.0                   720.0                     1.0   \n",
       "0                     0.0                   663.0                     0.0   \n",
       "0                     5.0                   384.0                     2.0   \n",
       "0                     0.0                   279.0                     0.0   \n",
       "0                     4.0                     0.0                     0.0   \n",
       "0                     1.0                     0.0                     0.0   \n",
       "0                     2.0                   640.0                     1.0   \n",
       "0                     2.0                   257.0                     1.0   \n",
       "0                     0.0                    33.0                     0.0   \n",
       "0                     0.0                     NaN                     NaN   \n",
       "\n",
       "   truth  (word_order, index, 3)  (word_order, score, 3)  \\\n",
       "0      1                   721.0                     1.0   \n",
       "0      2                   681.0                     0.0   \n",
       "0      3                   385.0                     2.0   \n",
       "0      4                   792.0                     0.0   \n",
       "0      5                    32.0                     0.0   \n",
       "0      6                   384.0                     0.0   \n",
       "0      7                   724.0                     0.0   \n",
       "0      8                    12.0                     1.0   \n",
       "0      9                   322.0                     0.0   \n",
       "0     10                     NaN                     NaN   \n",
       "\n",
       "   (word_order, index, 4)  (word_order, score, 4)  \n",
       "0                   736.0                     0.0  \n",
       "0                   695.0                     0.0  \n",
       "0                   291.0                     2.0  \n",
       "0                   285.0                     0.0  \n",
       "0                    36.0                     0.0  \n",
       "0                   387.0                     0.0  \n",
       "0                   701.0                     0.0  \n",
       "0                   276.0                     1.0  \n",
       "0                   384.0                     0.0  \n",
       "0                     NaN                     NaN  \n",
       "\n",
       "[10 rows x 41 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_set3 = final_set2\n",
    "final_set3[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries \n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as sm\n",
    "import statsmodels.api as sma\n",
    "from statsmodels.tools.eval_measures import mse\n",
    "from statsmodels.tools.tools import add_constant\n",
    "\n",
    "from sklearn import linear_model, model_selection, feature_selection, preprocessing\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\flori\\AppData\\Local\\Temp\\ipykernel_8036\\2565305869.py:2: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  final_set3 = final_set3.drop(['truth'], 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(num_occur, index, 0)</th>\n",
       "      <th>(num_occur, score, 0)</th>\n",
       "      <th>(num_occur, index, 1)</th>\n",
       "      <th>(num_occur, score, 1)</th>\n",
       "      <th>(num_occur, index, 2)</th>\n",
       "      <th>(num_occur, score, 2)</th>\n",
       "      <th>(num_occur, index, 3)</th>\n",
       "      <th>(num_occur, score, 3)</th>\n",
       "      <th>(num_occur, index, 4)</th>\n",
       "      <th>(num_occur, score, 4)</th>\n",
       "      <th>...</th>\n",
       "      <th>(word_order, score, 0)</th>\n",
       "      <th>(word_order, index, 1)</th>\n",
       "      <th>(word_order, score, 1)</th>\n",
       "      <th>(word_order, index, 2)</th>\n",
       "      <th>(word_order, score, 2)</th>\n",
       "      <th>(word_order, index, 3)</th>\n",
       "      <th>(word_order, score, 3)</th>\n",
       "      <th>(word_order, index, 4)</th>\n",
       "      <th>(word_order, score, 4)</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>183</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>569</td>\n",
       "      <td>3</td>\n",
       "      <td>710</td>\n",
       "      <td>3</td>\n",
       "      <td>342</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>293.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>720.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>721.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>736.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>728</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>282</td>\n",
       "      <td>8</td>\n",
       "      <td>691</td>\n",
       "      <td>8</td>\n",
       "      <td>272</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>701.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>663.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>681.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>695.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>273</td>\n",
       "      <td>21</td>\n",
       "      <td>544</td>\n",
       "      <td>10</td>\n",
       "      <td>761</td>\n",
       "      <td>8</td>\n",
       "      <td>858</td>\n",
       "      <td>7</td>\n",
       "      <td>224</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>385.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>291.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>572</td>\n",
       "      <td>19</td>\n",
       "      <td>639</td>\n",
       "      <td>8</td>\n",
       "      <td>108</td>\n",
       "      <td>7</td>\n",
       "      <td>148</td>\n",
       "      <td>7</td>\n",
       "      <td>736</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>279.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>792.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>510</td>\n",
       "      <td>8</td>\n",
       "      <td>408</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>621</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>61.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>259</td>\n",
       "      <td>4</td>\n",
       "      <td>963</td>\n",
       "      <td>4</td>\n",
       "      <td>633</td>\n",
       "      <td>3</td>\n",
       "      <td>900</td>\n",
       "      <td>3</td>\n",
       "      <td>920</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>793.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>724.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>259</td>\n",
       "      <td>4</td>\n",
       "      <td>963</td>\n",
       "      <td>4</td>\n",
       "      <td>633</td>\n",
       "      <td>3</td>\n",
       "      <td>900</td>\n",
       "      <td>3</td>\n",
       "      <td>920</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>95.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>724.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>502.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>700</td>\n",
       "      <td>12</td>\n",
       "      <td>494</td>\n",
       "      <td>7</td>\n",
       "      <td>296</td>\n",
       "      <td>6</td>\n",
       "      <td>525</td>\n",
       "      <td>6</td>\n",
       "      <td>476</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>337.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>166</td>\n",
       "      <td>7</td>\n",
       "      <td>444</td>\n",
       "      <td>5</td>\n",
       "      <td>259</td>\n",
       "      <td>4</td>\n",
       "      <td>963</td>\n",
       "      <td>4</td>\n",
       "      <td>106</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>141.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>984</td>\n",
       "      <td>13</td>\n",
       "      <td>700</td>\n",
       "      <td>12</td>\n",
       "      <td>96</td>\n",
       "      <td>8</td>\n",
       "      <td>521</td>\n",
       "      <td>7</td>\n",
       "      <td>494</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>296.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98 rows  41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    (num_occur, index, 0)  (num_occur, score, 0)  (num_occur, index, 1)  \\\n",
       "0                     183                      5                     40   \n",
       "0                     728                     10                      0   \n",
       "0                     273                     21                    544   \n",
       "0                     572                     19                    639   \n",
       "0                     510                      8                    408   \n",
       "..                    ...                    ...                    ...   \n",
       "0                     259                      4                    963   \n",
       "0                     259                      4                    963   \n",
       "0                     700                     12                    494   \n",
       "0                     166                      7                    444   \n",
       "0                     984                     13                    700   \n",
       "\n",
       "    (num_occur, score, 1)  (num_occur, index, 2)  (num_occur, score, 2)  \\\n",
       "0                       4                    569                      3   \n",
       "0                       9                    282                      8   \n",
       "0                      10                    761                      8   \n",
       "0                       8                    108                      7   \n",
       "0                       6                     18                      5   \n",
       "..                    ...                    ...                    ...   \n",
       "0                       4                    633                      3   \n",
       "0                       4                    633                      3   \n",
       "0                       7                    296                      6   \n",
       "0                       5                    259                      4   \n",
       "0                      12                     96                      8   \n",
       "\n",
       "    (num_occur, index, 3)  (num_occur, score, 3)  (num_occur, index, 4)  \\\n",
       "0                     710                      3                    342   \n",
       "0                     691                      8                    272   \n",
       "0                     858                      7                    224   \n",
       "0                     148                      7                    736   \n",
       "0                      23                      5                    621   \n",
       "..                    ...                    ...                    ...   \n",
       "0                     900                      3                    920   \n",
       "0                     900                      3                    920   \n",
       "0                     525                      6                    476   \n",
       "0                     963                      4                    106   \n",
       "0                     521                      7                    494   \n",
       "\n",
       "    (num_occur, score, 4)  ...  (word_order, score, 0)  \\\n",
       "0                       2  ...                       5   \n",
       "0                       8  ...                       7   \n",
       "0                       6  ...                       6   \n",
       "0                       6  ...                       4   \n",
       "0                       5  ...                       4   \n",
       "..                    ...  ...                     ...   \n",
       "0                       3  ...                       8   \n",
       "0                       3  ...                       4   \n",
       "0                       4  ...                       7   \n",
       "0                       4  ...                       8   \n",
       "0                       7  ...                       5   \n",
       "\n",
       "    (word_order, index, 1)  (word_order, score, 1)  (word_order, index, 2)  \\\n",
       "0                    293.0                     1.0                   720.0   \n",
       "0                    701.0                     0.0                   663.0   \n",
       "0                      3.0                     5.0                   384.0   \n",
       "0                      6.0                     0.0                   279.0   \n",
       "0                     61.0                     4.0                     0.0   \n",
       "..                     ...                     ...                     ...   \n",
       "0                    793.0                     2.0                    95.0   \n",
       "0                     95.0                     4.0                   724.0   \n",
       "0                    337.0                     1.0                     NaN   \n",
       "0                    141.0                     4.0                   102.0   \n",
       "0                    296.0                     3.0                    48.0   \n",
       "\n",
       "    (word_order, score, 2)  (word_order, index, 3)  (word_order, score, 3)  \\\n",
       "0                      1.0                   721.0                     1.0   \n",
       "0                      0.0                   681.0                     0.0   \n",
       "0                      2.0                   385.0                     2.0   \n",
       "0                      0.0                   792.0                     0.0   \n",
       "0                      0.0                    32.0                     0.0   \n",
       "..                     ...                     ...                     ...   \n",
       "0                      2.0                   195.0                     0.0   \n",
       "0                      0.0                   502.0                     0.0   \n",
       "0                      NaN                     NaN                     NaN   \n",
       "0                      3.0                   195.0                     3.0   \n",
       "0                      3.0                    29.0                     2.0   \n",
       "\n",
       "    (word_order, index, 4)  (word_order, score, 4)   y  \n",
       "0                    736.0                     0.0   1  \n",
       "0                    695.0                     0.0   2  \n",
       "0                    291.0                     2.0   3  \n",
       "0                    285.0                     0.0   4  \n",
       "0                     36.0                     0.0   5  \n",
       "..                     ...                     ...  ..  \n",
       "0                    724.0                     0.0  94  \n",
       "0                      NaN                     NaN  95  \n",
       "0                      NaN                     NaN  96  \n",
       "0                     62.0                     2.0  97  \n",
       "0                     30.0                     1.0  98  \n",
       "\n",
       "[98 rows x 41 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_set3['y'] = final_set3['truth']\n",
    "final_set3 = final_set3.drop(['truth'], 1)\n",
    "final_set3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(num_occur, index, 0)             -0.088007\n",
       "(num_occur, score, 0)             -0.187735\n",
       "(num_occur, index, 1)              0.036880\n",
       "(num_occur, score, 1)             -0.076261\n",
       "(num_occur, index, 2)             -0.063407\n",
       "(num_occur, score, 2)             -0.128061\n",
       "(num_occur, index, 3)             -0.168653\n",
       "(num_occur, score, 3)             -0.159853\n",
       "(num_occur, index, 4)              0.034847\n",
       "(num_occur, score, 4)             -0.144217\n",
       "(percentage_of_terms, index, 0)    0.026640\n",
       "(percentage_of_terms, score, 0)   -0.169683\n",
       "(percentage_of_terms, index, 1)    0.070514\n",
       "(percentage_of_terms, score, 1)   -0.079468\n",
       "(percentage_of_terms, index, 2)   -0.149705\n",
       "(percentage_of_terms, score, 2)   -0.102343\n",
       "(percentage_of_terms, index, 3)   -0.016807\n",
       "(percentage_of_terms, score, 3)    0.019962\n",
       "(percentage_of_terms, index, 4)   -0.045489\n",
       "(percentage_of_terms, score, 4)   -0.002568\n",
       "(td-idf, index, 0)                -0.201462\n",
       "(td-idf, score, 0)                -0.034749\n",
       "(td-idf, index, 1)                -0.196263\n",
       "(td-idf, score, 1)                -0.093650\n",
       "(td-idf, index, 2)                -0.127336\n",
       "(td-idf, score, 2)                -0.059986\n",
       "(td-idf, index, 3)                -0.070057\n",
       "(td-idf, score, 3)                -0.105149\n",
       "(td-idf, index, 4)                -0.017236\n",
       "(td-idf, score, 4)                -0.099558\n",
       "(word_order, index, 0)             0.415397\n",
       "(word_order, score, 0)             0.016328\n",
       "(word_order, index, 1)             0.060298\n",
       "(word_order, score, 1)             0.025704\n",
       "(word_order, index, 2)             0.155283\n",
       "(word_order, score, 2)             0.165187\n",
       "(word_order, index, 3)             0.128043\n",
       "(word_order, score, 3)             0.176349\n",
       "(word_order, index, 4)            -0.023863\n",
       "(word_order, score, 4)             0.205425\n",
       "y                                  1.000000\n",
       "Name: y, dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = final_set3\n",
    "data.corr()['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['a'] = data[data.columns[0]]\n",
    "data['b'] = data[data.columns[10]]\n",
    "data['c'] = data[data.columns[20]]\n",
    "data['d'] = data[data.columns[30]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.212</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.169</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   4.912</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 30 Jul 2022</td> <th>  Prob (F-statistic):</th>  <td>0.00146</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>00:11:52</td>     <th>  Log-Likelihood:    </th> <td> -365.25</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    78</td>      <th>  AIC:               </th> <td>   740.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    73</td>      <th>  BIC:               </th> <td>   752.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   53.5073</td> <td>    6.805</td> <td>    7.863</td> <td> 0.000</td> <td>   39.945</td> <td>   67.070</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>a</th>         <td>   -0.0085</td> <td>    0.011</td> <td>   -0.812</td> <td> 0.419</td> <td>   -0.029</td> <td>    0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>b</th>         <td>   -0.0147</td> <td>    0.024</td> <td>   -0.620</td> <td> 0.537</td> <td>   -0.062</td> <td>    0.032</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>c</th>         <td>   -0.0177</td> <td>    0.011</td> <td>   -1.550</td> <td> 0.125</td> <td>   -0.040</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>d</th>         <td>    0.1073</td> <td>    0.029</td> <td>    3.756</td> <td> 0.000</td> <td>    0.050</td> <td>    0.164</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 4.184</td> <th>  Durbin-Watson:     </th> <td>   2.150</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.123</td> <th>  Jarque-Bera (JB):  </th> <td>   2.134</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.078</td> <th>  Prob(JB):          </th> <td>   0.344</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.205</td> <th>  Cond. No.          </th> <td>1.39e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.39e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.212\n",
       "Model:                            OLS   Adj. R-squared:                  0.169\n",
       "Method:                 Least Squares   F-statistic:                     4.912\n",
       "Date:                Sat, 30 Jul 2022   Prob (F-statistic):            0.00146\n",
       "Time:                        00:11:52   Log-Likelihood:                -365.25\n",
       "No. Observations:                  78   AIC:                             740.5\n",
       "Df Residuals:                      73   BIC:                             752.3\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     53.5073      6.805      7.863      0.000      39.945      67.070\n",
       "a             -0.0085      0.011     -0.812      0.419      -0.029       0.012\n",
       "b             -0.0147      0.024     -0.620      0.537      -0.062       0.032\n",
       "c             -0.0177      0.011     -1.550      0.125      -0.040       0.005\n",
       "d              0.1073      0.029      3.756      0.000       0.050       0.164\n",
       "==============================================================================\n",
       "Omnibus:                        4.184   Durbin-Watson:                   2.150\n",
       "Prob(Omnibus):                  0.123   Jarque-Bera (JB):                2.134\n",
       "Skew:                           0.078   Prob(JB):                        0.344\n",
       "Kurtosis:                       2.205   Cond. No.                     1.39e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.39e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data\n",
    "\n",
    "train,test = model_selection.train_test_split(X,train_size=0.80)\n",
    "\n",
    "model = sm.ols(formula='y ~ 1 + a + b + c + d', \n",
    "               data=train).fit()\n",
    "\n",
    "modelforout = model \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "fig = sma.graphics.influence_plot(modelforout, ax=ax, criterion=\"cooks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "res = model.resid # residuals\n",
    "fig = sma.qqplot(res)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULT 1 : CARGILL CONFIRMS WHITE SUGAR SALE TO INDIA\n",
      "  Londonbased trader Cargill UK Ltd\n",
      "  confirmed it sold o ...\n",
      "RESULT 2 : INDIA FOODGRAIN TARGET 160 MLN TONNES IN 198788\n",
      "  Indias national foodgrain target has\n",
      "  been fixed  ...\n",
      "RESULT 3 : INDIA OILSEED OUTPUT FORECAST TO RISE\n",
      "  Indias oilseed output is expected to\n",
      "  rise to 1225 mln tonn ...\n"
     ]
    }
   ],
   "source": [
    "term = input(\"search: \")\n",
    "rank(term)\n",
    "# India"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To rework\n",
    "\n",
    "# term = input(\"search: \")\n",
    "# try:\n",
    "#     result = rank(term)\n",
    "#     result\n",
    "#     feedback = input(\"were these articles helpful?, (Y/N): \")\n",
    "#     if feedback == \"Y\":\n",
    "#         np.save('correct_search.npy', worddic) \n",
    "#     else:\n",
    "#         print(\"sorry it was not helpful, try again\")\n",
    "# except:\n",
    "#     print(\"no results found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Improvments\n",
    "* BM25\n",
    "* Bert pretrained tranformers\n",
    "* Feature extraction\n",
    "* Vector space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "af8259ad5c1c9c7a69bd6ea085234cf8fd3a6a37a71ca551828b314c4d89b0ad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
